[{"content":"Have you ever felt that the daily scrum offers no value? That we are wasting some precious time and getting everybody tired at the same time?\nI decided to write this blog post, in order to challenge the formalistic way in which the daily scrum is often run and share an alternative format for it. I have been using this format for over 3 years now. I had to find myself as a new team member to an existing team to notice how useful it has been and to remember that it is not the default way to go.\nOur daily scrum was exhibiting some dysfunctional symptoms back then and we decided to adopt this approach as an experiment. It turned out so successful that we never changed it - although we tweaked it a few times. Today, I don\u0026rsquo;t remember if this technique was based on something I read at the time or not. Feel free to point me to any references that deserve credit in the comments section.\n# Symptoms Before changing anything, we have to learn to identify the cases that call for change. For this purpose, I have listed some symptoms that I find to be good indicators. Let\u0026rsquo;s go over them.\n# No collaboration During the daily scrum, team members share their input, but no fruitful communication takes place. To better understand this, let\u0026rsquo;s think of the following hypothetical daily scrum situations:\nSituation #1: Mark: \u0026ldquo;Yesterday, I finished the implementation and opened a PR for this PBI. Today, I will start working on this one until I get some review feedback\u0026rdquo;.\nSituation #2: Mark: \u0026ldquo;Yesterday, I finished the implementation and opened a PR for this PBI. Can somebody review it, please?\u0026rdquo; Helen: \u0026ldquo;I would review it, but I don\u0026rsquo;t have time today. I will be able to review it tomorrow though.\u0026rdquo; Jason: \u0026ldquo;I can do it. Let\u0026rsquo;s just make sure to upload it in a test environment too.\u0026rdquo; Mark: \u0026ldquo;Thanks, guys. I\u0026rsquo;ll upload it and then I\u0026rsquo;ll work on this PBI until I hear back from you.\u0026rdquo;\nMark is sharing the exact same input in both cases, but notice how the work progresses in the second situation. In the first case, the team is not collaborating.\n# Monologue As mentioned above, the daily scrum is all about collaboration. If people are only speaking when their turn is up, how are they collaborating? Instead, a healthy team should be syncing and planning during the session. We should be hearing things like \u0026ldquo;Shall I use the test environment to test this?\u0026rdquo;, \u0026ldquo;I will release after the scrum. Do you want me to wait for this to be merged too?\u0026rdquo;, \u0026ldquo;Shall I merge this to your branch or to develop?\u0026rdquo;, \u0026ldquo;Do you need any help with this or shall I pick something up from the To-Dos?\u0026rdquo;.\nPeople not being fully engaged, being indifferent and only talking when their turn is up is a sign that clearly shows that the session is dysfunctional.\n# No planning ahead The daily scrum is supposed to be a planning session. Not a reporting session. Yes, we share the latest developments, but we do so in order to plan the next 24 hours. Try to keep track of the planning/reporting ratio. If it decreases, it is a very bad sign. Of course, this cannot be easily measured, but keep an eye on it and try to draw some conclusions.\n# Stuck PBIs In scrum, we are supposed to be delivering value fast. It doesn\u0026rsquo;t make sense to have a bunch of PBIs stuck at the \u0026ldquo;Review\u0026rdquo; swimlane for 3 days and picking up new work instead of reviewing the open PRs. The daily scrum is the time and place to make these decisions if they are not made during the day.\nBottlenecks in the sprint board can be an indication of poor daily scrums. Of course, the root cause may be different here, but when we see jammed swimlanes we ought to think of the daily scrum too.\n# My PBI Often you may hear people use phrases like \u0026ldquo;Yesterday, I finished the implementation in my PBI\u0026rdquo;. This is a highly problematic situation, as this single phrase implies that the team members are not thinking of the sprint\u0026rsquo;s work in a collective way. They work in an isolated way and this can impede their understanding of success.\nCompleting \u0026ldquo;my\u0026rdquo; PBI while my teammate struggles doesn\u0026rsquo;t make the sprint a success. This doesn\u0026rsquo;t mean that the team members are selfish. All I am trying to say is that software engineering is a team sport and it takes effort to deeply understand this and change your day-to-day work habits accordingly.\n# Another way The typical format most teams that I know of use is the \u0026ldquo;What did I do yesterday? What will I do today? Do I have any impediments?\u0026rdquo;. I usually call this the \u0026ldquo;per-person\u0026rdquo; format. However, remember that the format is up to the team to decide. Consulting the scrum guide we find the following:\nThe Developers can select whatever structure and techniques they want, as long as their Daily Scrum focuses on progress toward the Sprint Goal and produces an actionable plan for the next day of work.\n# Overview An alternative to the \u0026ldquo;per-person\u0026rdquo; format would be the \u0026ldquo;per-PBI\u0026rdquo; format. With this approach, the team works the sprint board right to left and top to bottom. Every open PBI is discussed and the focus is on what the team needs to do in the next 24 hours to move this PBI towards the right (\u0026ldquo;Done\u0026rdquo; swimlane).\nLet\u0026rsquo;s use an example to understand it better. Assuming that the team\u0026rsquo;s sprint backlog is the following:\nThe daily scrum would first focus on the topmost PBI in the \u0026ldquo;Delivered\u0026rdquo; swimlane. They would ask if it can be considered done. If yes, it would be moved to the \u0026ldquo;Done\u0026rdquo; swimlane. If not, a team member could undertake to check if it works as expected and move it to \u0026ldquo;Done\u0026rdquo;. Then they would do the same for the second \u0026ldquo;Delivered\u0026rdquo; PBI if there was any and so on and so forth.\nThey would then move to the \u0026ldquo;Merged\u0026rdquo; swimlane, focusing on how could they get these tickets to \u0026ldquo;Delivered\u0026rdquo;. Would they deploy on production? If yes, who would undertake it? Are there any dependencies that need to be deployed as well? Who should be notified? These are the things that should be discussed during a healthy daily scrum.\nThe next step would be the \u0026ldquo;Review\u0026rdquo; swimlane, in which the team needs to ensure that the PBIs do not remain idle for review if there is the capacity from team members to review them. They could decide who gets to review what and share more context if needed. Priorities could be defined if time and/or capacity do not suffice for all the PBIs. Again, the focus would be on how to move these PBI to \u0026ldquo;Merged\u0026rdquo; within the next 24 hours.\nThen, they would briefly discuss the \u0026ldquo;In Progress\u0026rdquo; PBIs, sharing progress and impediments and making clarifications if needed. The last step would be to talk about starting new PBIs in the next 24 hours.\nFinally, there can be some time to share anything that needs to be shared and wasn\u0026rsquo;t already covered.\n# Advantages # Reduced lead time This format focuses on getting things done and delivering value. It\u0026rsquo;s all about what needs to be done within the next 24 hours to move this PBI to the next swimlane. Inevitably, this prioritizes closing the open PBIs over opening new ones. As we have already discussed in the Limiting work in progress post, this reduces the team\u0026rsquo;s lead time.\n# Focus shifts to planning Instead of discouraging interruptions while other team members are sharing their input, this format welcomes their contribution. Fostering dialogue in this way shifts the focus from reporting to planning. Team members communicate more and it\u0026rsquo;s all about moving the ticket to the right, instead of plainly sharing yesterday\u0026rsquo;s actions.\n# Teamwork mentality Furthermore, the transition from monologue to an intensely collaborative format builds stronger team relationships and a teamwork mentality. The team learns to function as a unit, as opposed to a set of individuals. They learn to cooperate and they understand that great results take more than an individual writing code. There is no \u0026ldquo;my PBI\u0026rdquo; anymore. There is \u0026ldquo;our work\u0026rdquo;.\n# Considerations # Longer daily scrums From my personal experience, I\u0026rsquo;ve noticed that the session sometimes tends to last longer with this format. This is a result of the increased dialogue. However, there can be a number of root causes behind this.\nThe first thing that should come into our minds is whether there are too many open PBIs. If yes, the team should focus on closing some of them before starting to work on new ones. It could also show that the team is getting dragged into long conversations, which could be kept shorter. Finally, maybe the team needs this extra time. Personally, I wouldn\u0026rsquo;t mind a slightly longer daily scrum so long as the conversation is fruitful and meaningful.\n# People feel left out Also, people whose work is not directly visible on the board (e.g. designers and product owners) could start to feel left out with this format. My advice would be to encourage them to contribute whenever needed in the conversation and to use the time at the end of the session to share their input if it wasn\u0026rsquo;t already shared.\n# Own the process Having shared this technique, which I have successfully used, it is important to understand that every team is different. Just because it worked for a team it doesn\u0026rsquo;t mean that it will also work for another one. Dogmatically applying a solution that worked for another team and expecting results goes against the very nature of the agile mindset.\nI would not advise against applying this format, but rather use it as a starting point. Call it an experiment and remember to evaluate this experiment. Then tweak it and run another experiment. Evaluate this one too. Then tweak it again. Chances are that the result that works for your team is different than the one I described. Maybe slightly different, maybe radically different. The point is to understand that the process is here to serve us and not the other way around. If it is not working, then change it to something that works. Make it your own.\n# Conclusion The daily scrum is a pivotal event that can make all the difference between a successful and a failed sprint. Often, it gets executed in a formalistic way, which offers no real value. There are a number of symptoms that can help us identify a dysfunctional daily scrum session, such as lack of planning for the next 24 hours, jammed swimlanes and people not engaging in conversation during the session.\nA different way to run the session can prove beneficial. I have successfully used what I call the \u0026ldquo;per-PBI\u0026rdquo; format to run daily scrums and I feel that it offers a series of advantages, such as reduced lead time and improved team cohesion. Along with it come some downsides, such as certain roles feeling left out and increased duration of the session.\nNo matter if we choose the \u0026ldquo;per-PBI\u0026rdquo; format or not, the responsibility of identifying the dysfunction and taking action to improve the situation lies with us, the software engineering team. So, I would strongly advise experimenting with different formats and tweaking the process until it serves the team.\n","date":"2022-11-06T00:00:00Z","image":"//localhost:1313/img/posts/a_different_way_to_run_the_daily_scrum.jpg","permalink":"//localhost:1313/a-different-way-to-run-the-daily-scrum/","title":"A different way to run the daily scrum"},{"content":"The test should pass now. Oh, it still fails. Why is that? I think I\u0026rsquo;ve missed this edge case. I\u0026rsquo;ll fix it by adding this line, here. Great, it passed, but another one fails now. That\u0026rsquo;s weird. I guess that this line broke the other case. Never mind, I\u0026rsquo;ll add this line too and this should fix both of them. Oh, now I\u0026rsquo;ve broken a bunch of them.\nHave you ever been in a situation like this? Do you relate to the train of thoughts? How long did it take you to get all the tests to pass? How did you feel when they finally passed? Creative, energized and ready to continue or relieved, exhausted and ready to take a break or call it a day? What if you had reverted the change as soon as it made a test fail and approached the problem from a different angle?\nThis is one of the key ideas behind test \u0026amp;\u0026amp; commit || revert (TCR), a programming workflow born during a Kent Beck workshop (and also attributed to Oddmund Strømme, Lars Barlindhaug, and Ole Johannessen). In this blog post, I will try to provide an overview of TCR.\nBefore we delve into it, let me add a small disclaimer. I have only scratched the surface of TCR. I have only used it in playground projects, with the sole purpose of understanding it. I have not used it in production code and I am definitely not advocating for it in this post. The intention of the post is to let you know that TCR is a thing and merely present some of its trade-offs that I have discovered.\n# The main idea During any typical programming workflow, we run the tests a lot. We definitely do so before committing the code. So, the idea behind TCR is that we should commit every time the tests pass. But there\u0026rsquo;s a catch. If we do commit every time the tests pass, we should also revert every time the tests fail. It\u0026rsquo;s simple but profound and powerful.\nApplying these two constraints locks us in a cycle. Exactly like TDD does, just with a different cycle. Since a failing test automatically reverts the code, there is no red state. We always keep the tests passing and we always find ourselves in the green state, the only state there is.\nsource: https://medium.com/@kentbeck_7670/test-commit-revert-870bbd756864\n# Why should I try it Now, I understand that TCR may sound extreme (to say the least). I can already hear the objections. \u0026ldquo;But I will be losing code\u0026rdquo;. \u0026ldquo;But I love the red state\u0026rdquo;. \u0026ldquo;But it sounds so frustrating\u0026rdquo;. \u0026ldquo;But why would I want to do that?\u0026rdquo;. These were also my first thoughts. So, let\u0026rsquo;s try to understand what do we stand to gain from giving TCR a chance.\n# Baby steps If there was a single lesson to be learned from practising TCR it would be the following:\nThe only way to go fast, it to go well\nThis is a quote from Uncle Bob, which has shaped my way of thinking around writing code like few others.\nThe core idea behind TCR is moving in small steps. Moving in baby steps. Tiny steps. Small enough to be sure that they keep the tests passing. Small enough not to risk losing a bunch of code if a test fails. The philosophy is \u0026ldquo;what is the next, small, steady step that I can take towards my goal?\u0026rdquo;.\nMoving forwards in small, seemingly insignificant steps can be surprisingly more beneficial than going back and forth.\n# Gamification Practice TCR for 10 minutes and you can\u0026rsquo;t help but notice the gamification element. Causing a test to fail feels like making a mistake in a video game and having to start over again. Gamification makes us have fun. And when we have fun we tend to be more creative and we tend to come up with better solutions (this is just my intuition, it is not backed by any study that I know of). Of course, this coin has two sides, but we will discuss this in-depth later on.\n# Improves refactoring Refactoring a piece of code takes discipline. It requires a series of small, confident steps. It requires keeping the tests green at all times. The truth is that, even with the aid of the IDE\u0026rsquo;s automated refactoring options, this is challenging.\nI find that TCR can be immensely helpful during the refactoring process. Any modification that breaks the tests gets automatically reverted. Therefore, by definition, all refactoring moves keep the tests green.\nBut there\u0026rsquo;s more in it. Refactoring moves that break the tests get reverted. They do not \u0026ldquo;survive\u0026rdquo; into commits. Only the ones that keep the tests passing \u0026ldquo;survive\u0026rdquo;. They get committed and eventually pushed and merged. This rings a bell, doesn\u0026rsquo;t it? This sounds a lot like a natural selection process for refactoring moves. Just the ones that display useful qualities (keep the tests passing) make it into commits. The accumulation of the effects of this continuous feedback is bound to make us more skilled in the long run. Let\u0026rsquo;s not get too carried away with the metaphor, but I strongly believe that applying TCR when refactoring can really improve our refactoring skills.\n# A tool for understanding legacy code TCR works wonderfully well as a learning tool. Assuming that we have a piece of legacy code that we want to understand. It\u0026rsquo;s natural that we start making assumptions when we read the code. Suppose we fire up the TCR script and express these assumptions as unit tests. If the assumption is correct, the test passes and we just learned for sure that the code does what we thought it did. In case the assumption was incorrect, the test fails and disappears. We learned what the code does not do. So, we just learned again.\nThis is like orally applying specification by example in a conversation with the author of the code. Except that the author might even be in a different company now. Except that there is way less room for a misunderstanding, as the specification is written in code. Except that we get to keep a comprehensive test suite when we are done.\nI learned about this fascinating technique when I came across this video, which illustrates it wonderfully.\n# Downsides Having listed some advantages, let\u0026rsquo;s also have a look at some inconveniencies that come with the TCR.\n# Losing stacktraces and test output I feel that one downside is too obvious to ignore. This is losing the stacktrace of a failed test. It\u0026rsquo;s natural. When a test fails, we want to understand why it failed. However, since the tests get reverted automatically, the stacktrace disappears.\nPerhaps there are ways around the issue, by carefully configuring the test command you use, but it was the very first thing that annoyed me when a test failed when I wasn\u0026rsquo;t expecting it.\nThis does not stop on stacktraces though. The test output in general is gone with the reverted code. It first bothered me when I used Spock\u0026rsquo;s @Unroll feature and a single case failed.\nUnconvenient as it might be, this is part of the process. TCR urges you to approach the problem from a different angle, or maybe opt for a smaller step. Debugging a failed test completely defeats the purpose.\n# Commit messages It should be obvious that practising TCR can easily create tens of tiny commits. Actually, it should do exactly that when done right. So, the questions that naturally follow are \u0026ldquo;what do I do with all those commits?\u0026rdquo; and \u0026ldquo;what about the commit messages?\u0026rdquo;.\nThese can be addressed in a number of ways. For instance, my preferred method is to add a default commit message (e.g. \u0026ldquo;WIP\u0026rdquo;). Then, when I reached the point in which I would originally commit if I was not using TCR, I would squash all these, tiny, WIP commits into a single one and reword it. Apart from this, there are other methods that would also work, like using the git diff list as the commit message.\nNevertheless, this constitutes a problem that should be solved and, one way or another, it\u0026rsquo;s an overhead.\n# Frustration The alter ego of the above-mentioned gamification aspect is the irritation that TCR can cause you. The rational first reaction to witnessing the code you\u0026rsquo;ve been writing over the past few minutes (or seconds) magically disappearing in front of your eyes is frustration. Sometimes even anger. While gamification can make one more creative, frustration can lead to bad-tempered decisions and hasty solutions.\nUnfortunately, this can lead to a vicious cycle. The more the code gets reverted, the worse your mood gets, which leads to more mistakes, which leads to the code getting reverted even more. Quite ironically, this is a good feature of TCR, because if you find yourself having your code reverted (say) 10 times in a row, perhaps that\u0026rsquo;s the best sign that you need to take a break.\nIn any case, I feel that this is perhaps the most interesting trade-off that TCR has to offer. The balance between having fun and feeling angry and disappointed is crucial. In other words, for TCR to be effective, sticking to the essence is key. And the essence is aiming for baby steps.\n# Open questions A programming workflow it\u0026rsquo;s open to customization and experimentation by its nature. TCR, being fairly new (created in 2018), leaves plenty of room for both. Let\u0026rsquo;s examine some of the aspects that remain open.\n# Reverting tests Writing a test only to have it reverted because it failed can be discouraging. Especially for people with a strong TDD background, who have worked hard to install the habit of writing a failing unit test first. This can be particularly disturbing for them. Maybe this is the reason why a variation suggests that the tests should not get reverted as part of the TCR process. In other words, when a test fails, the production code should get reverted, but not the tests.\nI strongly believe that different approaches may work better for different people. TCR is a tool. It\u0026rsquo;s merely means to an end and not an end in itself. So, I have deliberately chosen to include this topic in the open questions. I believe that either approach will work. So, some people will choose to revert the tests along with the production code and some people will not do so.\n# What happens with pushing We have already discussed the issue with the numerous, tiny commits, but when does the code get pushed during this workflow? Again, this is a matter of choice. Manually pushing after a bunch of small commits will work fine. Exactly like automatically pushing along with every tiny commit. The former diminishes the sense of \u0026ldquo;continuous delivery\u0026rdquo; that comes with TCR while the latter most likely requires a rebase and force push. The issue with the commit messages has to be resolved in either case. So, again, I would suggest customizing it to your preference.\n# Setting up the environment for TCR Practising TCR requires a little bit of setup. There should be an automated way to observe the source files and detect changes, run the tests and, depending on the outcome of the tests, either commit or revert the code. There are various ways in which this can be achieved. Personally, I used the following bash scripts:\na watch.sh script that observes the source code, detects changes on it and triggers the TCR script. #!/bin/bash while true; do inotifywait -r -e modify src ./tcr.sh done the tcr.sh script, that holds the base logic of TCR: #!/bin/bash source \u0026#34;scripts/test.sh\u0026#34; source \u0026#34;scripts/commit.sh\u0026#34; source \u0026#34;scripts/revert.sh\u0026#34; test \u0026amp;\u0026amp; commit || revert the test.sh script, which executes the unit tests #!/bin/bash function test() { echo \u0026#34;Testing changes...\u0026#34; ./gradlew test } the commit.sh script #!/bin/bash function commit() { echo \u0026#34;Committing and pushing changes\u0026#34; git add . \u0026amp;\u0026amp; git commit -m \u0026#34;WIP\u0026#34; \u0026amp;\u0026amp; git push } and the revert.sh script #!/bin/bash function revert() { echo \u0026#34;Reverting changes\u0026#34; git checkout . } I have created a playground github repository. It is set up for Kotlin and Spock and serves me for experimenting with TCR, but feel free to either grab the bash scripts or fork the repository and use it to play with TCR.\n# Conclusion TCR provides some exciting and fresh ideas. It focuses on small, steady steps, which accumulate to create progress. It gamifies programming and, among other things, it can improve refactoring and work as a tool for understanding legacy code.\nThere are disadvantages to be considered, such as losing the stacktraces and output of failed tests, dealing with countless tiny commits and dealing with frustration. There are also a lot of open questions, like whether or not tests should get reverted along with the production code or when should the code be pushed.\nTCR sounds extreme, but I am sure that people were thinking exactly the same about TDD when it first came out.\n","date":"2021-03-10T00:00:00Z","image":"//localhost:1313/img/posts/tcr.jpg","permalink":"//localhost:1313/test-commit-revert/","title":"Test \u0026\u0026 commit || revert"},{"content":"Almost 20 years past the authorship and signature of the Agile manifesto and its true message has gone astray. The residual believers of the original ideas of the Agile manifesto have found shelter in the Software Craftsmanship movement, but nowadays the roots of the problem lie far deeper than the lost ideas and the wasted potential to do things better.\nThe misinterpretation of the philosophy of the agile manifesto combined with the creation of a number of frameworks, certifications and job titles has resulted in a chaotic situation. A situation which not only faces the exact same problems that led to the creation of the Agile manifesto in the first place, but which results in increased complexity and work. This is a direct consequence of people following dogmatically some obscure guidelines which they do not understand in the first place.\nIf you are part of an agile organization, have you ever taken a step back to create distance between yourself and your work and reflected on how you do things in your organization? Is the Agile approach better than what you had before? If yes, why is it so? What adds true value? What has improved and in what way?\nThese questions should be easy to answer, especially by anyone who is part of an organization that has spent enormous amounts of effort and money in a so-called, agile transformation, and yet, they prove astonishingly difficult. In this blog post, I will try to put in words what I believe the true Agile mindset is.\n# The problem Before attempting to provide a solution, one has to really understand the problem. So, let\u0026rsquo;s try to delve into it. Let\u0026rsquo;s study the following, hypothetical case.\nA company decides to become Agile and use Scrum. An Agile coach is hired and the so-called Agile transformation begins. The offices are rearranged, new shiny boards are installed and Scrum Master and Product Owner roles are born and filled. Every two weeks a new sprint begins. Its goal is a chunk of the promised-to-the-client release in a few months time. People stand up for no more than 15 minutes a day, discussing their progress and coordinating. The walls are full of sticky notes describing tasks. The software engineers still write code in the exact same way they did before, but now in 2-week iterations. No other department has changed the way it works, apart from the engineering department.\nNow, I repeat that this is a hypothetical scenario, but to the extent of my knowledge, a very realistic and typical one. This \u0026ldquo;transformation\u0026rdquo; is doomed to fail. It is precisely this kind of \u0026ldquo;transformations\u0026rdquo; that have caused a lot of people to lose faith in the Agile way of working. This approach is fundamentally flawed. It completely misses the essence. It defeats the purpose. Situations like these are commonly described by the term Agile theater.\nLet\u0026rsquo;s examine what\u0026rsquo;s wrong with this approach. The core idea of the Agile mindset is that\nthe people who need the software (stakeholders/users) collaborate closely with the people who make the software and they are able to adjust the course as often as needed\nWe will discuss how this may be achieved later on, but first, let\u0026rsquo;s understand why the above-mentioned changes do not serve this goal.\nReleases are planned and promised to the customer with certain deadlines. This does not allow for adjusting the course. Despite the pseudo-iterations, the work is treated in a waterfall manner. The software engineers break the release work down to 2-week chunks, but that offers nothing without the rest of the stakeholders and the customer actively participating in that 2-week loop. The course cannot be adjusted.\nThe software engineers have changed nothing in the way they write code. Even if the stakeholders and the customer were actively engaged in the loop and even if the course was adjusted every two weeks or so, how could the software engineers respond to that? They couldn\u0026rsquo;t. If you were to take just one thing away from this post, let it be the following: Changing the process means nothing without changing the way code is written\nEverything seems Agile from the outside, but nothing is really changed. Hence the term Agile theater. There are neither hooks in the process nor the technical foundation required for constant inspection and adaption. Feedback is not flowing between the software engineers and the stakeholders/users.\n# Feedback loops A truly agile way of working requires constant adaptations. Constant adaptations require a constant flow of feedback. Therefore, lots of feedback loops are needed. The shorter these loops are, the more adaptation they will allow for. The sooner one receives feedback on one\u0026rsquo;s action, the easier it is to amend mistakes.\nA feedback loop may sound like a subtle concept, but if you think about it\u0026rsquo;s powerful and it\u0026rsquo;s everywhere:\nScrum events are feedback loops. During the daily scrum, the team adapts the upcoming day\u0026rsquo;s work based on the feedback on yesterday\u0026rsquo;s work. During the sprint retrospective, the team generates feedback on the previous sprint and makes amendments for the upcoming sprint. During the sprint review, the stakeholders provide feedback on the delivered increment and the product backlog gets adjusted based on it (sprint review is so misunderstood that perhaps deserves a blog post of its own).\nTest-Driven Development (TDD) is a feedback loop. A very short one actually (when done right). The engineers set up a loop between themselves and the code. A change in the code produces immediate feedback. Did the change work? Did it break anything? Does the code written in the last few seconds need modifications? This actually constitutes the fastest feedback software engineers will ever get on their code.\nPair programming is a feedback loop. This loop is set up between the two engineers working together. The code one writes produces feedback from the other, which changes the code, which changes the feedback and so on and so forth.\nCode reviews are a feedback loop. Actually, it is the exact same loop with pair programming, except that it involves more people and the feedback flows significantly slower.\n# Enabling inspection and adaptation Feedback loops are enablers. Remember, we need to adjust our course as often as needed based on feedback. How can we adapt the product to feedback if we don\u0026rsquo;t get any from the stakeholders?\nSuppose we do get feedback on a regular basis. How can we utilize it if our technical practices do not support changing easily? The XP technical practices (TDD, pair programming, refactoring etc) enable software engineers to work in a way that expects frequent changes and - as discussed - they constitute feedback loops.\nFor our feedback loops to be valuable, not only do they need to be in place, but we need to make sure that they are short as well. Getting feedback after a 6-month release, in order to plan the next one, technically is a feedback loop. Not one that can be useful in Agile environments though. Six months is an aeon on a typical market and it is almost impossible to meaningfully predict the needs imposed by the market in such a long period. The release features are doomed to become obsolete to some extent.\nA unit test suite that needs 15 minutes to run is technically a feedback loop, but again, not a useful one. There is no way an engineer can perform TDD using this test suit. The TDD cycle is going to be way too slow to be useful.\nTo work in an Agile way we need to strive to keep our feedback loops as short as possible. We need to shrink them, so long as we keep them meaningful. The shorter the loop the quicker the feedback and therefore the adaptation.\n# Scaffolding Now let\u0026rsquo;s assume that we could do all these things. We could flip a magic switch and, starting from tomorrow, we could create more feedback loops, shorten them, use their feedback to adapt, embrace all XP technical practices etc.\nWhy would it make sense to use an Agile framework then? Changes create discomfort. It\u0026rsquo;s natural. Especially when they are radical and they concern the way we work every day. What would Scrum, Kanban, SAFe, LeSS, you-name-it provide that would justify this tremendous effort and energy needed to adopt them? Take a minute to reflect before proceeding.\nMy answer would be a resounding \u0026ldquo;nothing\u0026rdquo;. If we already enjoy all the merits that these frameworks bring, why bother adopting them?\nHowever, this magic switch does not exist. That\u0026rsquo;s were the frameworks come into play. They can be used to initiate the transition and help us create all these good habits. They can provide the time and place for feedback loops to be created and their feedback to be used. They would put us on the right track and help us identify what works best for us. They can be our guide to the exploration of the shift to the Agile mindset. They are great as long as they are used as scaffolding.\nGetting passed the scaffolding stage they should be gradually thrown away, giving way to our own, unique Agile process as it emerges. The process that works best for us.\nFailing to throw them away and adjust the process in a way that suits our needs and work defeats the purpose. Frameworks are there to put us on the right track and not be blindly followed to the letter, in a ritualistic way. Applying them dogmatically only implies a cargo cult mentality. Doing things without understanding why and expecting certain results to just happen is precisely the definition of cargo cult.\nThe Agile mindset is centered around autonomous teams, working in a self-organized manner. What are the chances that two autonomous, self-organized teams will need and use the exact same process to the letter?\nIf a process is the same for everyone, it is not Agile\nDogmatically following a framework (e.g. Scrum) to the letter results in everyone doing exactly the same.\nDon\u0026rsquo;t get me wrong. The process that works best for you may be ridiculously close to Scrum (or Kanban etc). I only suggest that these frameworks need not be followed blindly to the letter.\n# Never stop learning Being a Scrum Master myself, I\u0026rsquo;ve fallen prey to the frameworks too. During my early days getting passed the Scrum Master training, if the daily stand-up was reaching the 16th minute, I thought that my whole professional world was falling apart. I felt obliged to make the team see that is should have been stopped earlier, even if the team wrapped up and finished the stand-up in a total of 16-17 minutes. It still felt wrong. I was myself a victim of the above-mentioned cargo cult mentality.\nHowever, thinking back, I find it quite reasonable. It\u0026rsquo;s a natural step in the learning process. To master something one has to first understand it perfectly and know it inside out. One has to apply it and practise it a lot until one is able to decipher its true meaning and master the skill.\nWorking with a team will not make you a Scrum Master / Product Owner / Agile Software engineer. A certification will definitely not make you one (and I own a certification too). Instead, go out in the industry and work with teams. Listen closely and try to help them. Take time to reflect and identify what works. Above all, never stop learning and be open to changing your mind or standpoint.\n# Conclusion Almost 20 years ago a few people got together and tried to uncover better ways to make software. The message got lost in the way. The intention became misunderstood. The end result is a cargo cult mentality that follows rules blindly, creating more problems than it solves. Job titles and certifications are born, but these don\u0026rsquo;t change the way software is being written.\nAgility is based on the idea of constant adaptation based on feedback. Feedback from the stakeholders, the users, the market, the code and our fellow software engineers. The way to get this is to establish feedback loops and make sure that they are short enough to have meaning and be helpful. These will enable constant inspection and adaptation.\nAgile frameworks are out there to put people on the right track and not to be followed religiously. They are tools and should be used to help us uncover our better ways of making software. As time goes by they should naturally give way to the process that works best for us. A continuous learning mentality will support this gradual transition.\n","date":"2020-11-08T00:00:00Z","image":"//localhost:1313/img/posts/agile_theater.jpg","permalink":"//localhost:1313/agile-theater/","title":"Agile theater"},{"content":"How would you identify bottlenecks in your team\u0026rsquo;s process? How would you surface them? How would you encourage the team to increase collaboration? How would you decrease lead times and increase the bus factor?\nWorking in an Agile way is far from following a predefined set of rules. On the contrary, is all about inspecting and adapting. It\u0026rsquo;s about finding what works best for the team and it is an ever-ending process. This includes a lot of experimentation. Adopting something new for a few days/weeks, evaluating its benefits and either keep it or discard it before you move on to the next experiment. A team not chasing continuous improvement cannot be Agile.\nThis post is all about experimenting with limiting work-in-progress (WIP). Applying WIP limits is a beautiful technique, originated in Kanban, but I believe it can be applied very effectively on Scrum teams too. Before we analyze the technique though, let\u0026rsquo;s briefly go over the symptoms that may push a team towards experimenting with WIP limits in the first place.\n# Symptoms Let\u0026rsquo;s imagine a Scrum team consisting of five software engineers is in the middle of a two-week sprint. The first five stories in-progress and the team is juggling among them, trying to advance all of them at the same time.\nThere is a number of issues that one could note in the above-mentioned situation. I would argue that the first one is the lack of focus. Focus is one of the five Scrum values. It is a quality that without it, Scrum can never work. It is as simple as that. Although the team is focused on a macro-level (there is a two-week sprint with a well-defined sprint goal), the lack of focus on a micro-level is resounding.\nSecondly, there is a total absence of priority. The stories in a sprint board are sorted based on their priority. The higher the priority of the story, the higher on the board the story is. Trying to put this priority in words, it would be something in the following lines: \u0026ldquo;if as a team we manage to get a single story done in the sprint, let this be the topmost one. If we get two stories done, let them be the first two ones\u0026rdquo; and so on and so forth. A team that is working on five stories in parallel does not honour the notion of priority and to some extent, it is missing part of the essence of Scrum as a framework.\nFurthermore, a team in such a situation exhibits chemistry issues. Perhaps people do not enjoy working with each other or they believe that it is not efficient. Whatever the reason, there is no teamwork (e.g. pair programming) and the team is behaving like a set of individuals instead. However, great results are more often than not delivered by great teams.\nSuch a workflow has the tendency to lead to a big bang release towards the end of the sprint. This allows for no time to react to a release that caused issues and it does not give a smooth, steady flow of value to the stakeholders and the users. A failed release could cause the sprint to fail.\nLastly, this way of working inevitably leads to significantly small bus factors, usually to a bus factor of one or two. This impedes collective code ownership and in case an individual leaves the team, a knowledge gap is also created.\nI could continue commenting on this situation, but I believe that I have made my point. So, (hopefully) agreeing that this is a problematic situation, let\u0026rsquo;s go over a technique that can mitigate it.\n# What is a WIP limit Limiting work-in-progress is a very simple technique.\nA WIP limit is a number indicating the maximum items (e.g. stories, tasks) tha may be in-progress at any given moment.\nSo, if a team has a WIP limit of two stories, it can only work on two stories at the same time at any given moment. In order to start working on a third one, one of the two previously in-progress has to be done.\nIt originates from Kanban and there it applies to tasks on the team\u0026rsquo;s Kanban board. In Scrum, it can either be applied to stories or story tasks, depending on what works best for the team. Also, the very definition of in-progress may be adjusted according to the team\u0026rsquo;s needs. For instance, a story can be considered in-progress until it is code-reviewed or until it is deployed to production. The limits may span on a number of different swimlanes as well and each swimlane can have its own limit.\n# Can this be applied to scrum? It would be reasonable to wonder whether there would be any sense in applying such a technique to Scrum, given that the work is bound by the sprint duration. One could argue that WIP limits in Kanban make sense because there is no such boundary.\nHowever, considering all the above-mentioned symptoms, which could be more or less addressed by applying a WIP limit, I feel that it is meaningful. As a matter of fact, we have applied it in teams that I have been a part of with considerable success.\nIn case applying a Kanban technique to Scrum feels like breaking the rules, let\u0026rsquo;s always keep in mind that being Agile is all about the culture. Blindly adopting a set of rules is a cargo cult mentality that leads nowhere. If you ask me, if WIP limits serve us, let\u0026rsquo;s use them.\n# WIP limit benefits Let\u0026rsquo;s examine some of the benefits that a team would expect by applying WIP limits.\n# Reduced lead time Lead time is a metric, expressing the time elapsed between starting and completing an item of work.\nA Scrum team\u0026rsquo;s lead time is the time required between the team committing to a story (sprint planning) and the story being done.\nLet\u0026rsquo;s study again the hypothetical example of the Scrum team of five software engineers in the middle of the sprint with five stories in-progress. Let\u0026rsquo;s also assume that the team manages to complete all five stories at the very last day of the sprint and that these were all the stories in this sprint. What is the lead time of the team?\nEach of the five stories took nine days (the working days of a two-week sprint excluding the Scrum events day) to complete, so the team\u0026rsquo;s average lead time is\n(5 * 9) / 5 = 9 days\nLet\u0026rsquo;s assume that the team had applied a WIP limit of two. This means that no more than two stories could be worked on parallel. The first two stories could perhaps be done in the third and fourth day respectively. The next two stories could be completed in the seventh and eight days respectively and the last story could be completed on the very last day of the sprint. Let\u0026rsquo;s calculate again the team\u0026rsquo;s average lead time.\n(3 + 4 + 7 + 8 + 9) 5 = 5.4 days\nThese numbers are fictitious of course, but they are meant to illustrate the point. As a matter of fact, feel free to fiddle with the numbers and inspect the results. The result will always be less than nine. I feel that plugging some reasonable numbers in the formula will result in an average lead time significantly below 9, like 5.4.\nThis essentially means that the team delivered value early. The stakeholders and product users started having increments on the third and fourth day of the sprint instead of the ninth.\n# Teamwork A WIP limit is essentially the application of a restriction. A restriction on the amount of work that can be concurrently undertaken. However, team members remain the same despite the restriction. Hence, the smaller the number of stories or tasks that can be simultaneously in-progress the more the level of cooperation among the team members has to increase.\nThink about it. In a very simplistic scenario, a team of two software engineers with a WIP limit of one would always pair (in the case where the WIP limit is applied to tasks) or - at least - work on the same story (in the case where the WIP limit is applied to stories). A team of - say - 5 software engineers with a WIP limit of four would mean that there should always be at least one pair. Reduce this to a WIP limit of three and the pairs become at 2 at all given moments.\nPairing is a more intense form of collaboration, but working on the same story is still more collaborative than two software engineers working on different stories. Given sufficient time, this restriction will strengthen the team bonds and will help build the right chemistry.\n# Bus factor Increased teamwork goes hand in hand with increased bus factors. I believe this is quite straightforward. The more often two or more people work on the same story, the more the parts of the code that more people will be familiar with. On the contrary, a team whose members tend to work alone on a story will end up with a codebase full of parts that only a single software engineer is familiar with.\n# Identify bottlenecks Applying a WIP limit is a tailor-made technique for surfacing bottlenecks in a team\u0026rsquo;s process. Let\u0026rsquo;s imagine a scenario in which a team uses the flow \u0026ldquo;todo\u0026rdquo;, \u0026ldquo;doing\u0026rdquo;, \u0026ldquo;review\u0026rdquo;, \u0026ldquo;delivered\u0026rdquo; and then \u0026ldquo;done\u0026rdquo;. It undertakes stories and when the code is written, the story is passed to the rest of the team for code review. The engineer(s) that worked on this story naturally grab the next one until this one gets reviewed. It is quite common for teams to end up with a pile of stories that should get reviewed towards the end of the sprint. This, of course, leads to rushed code reviews and a big bang release with a dozen features in it. This is a typical case of a bottleneck in the process.\nNow, let\u0026rsquo;s imagine that this team applies some WIP limits. Remember that these may span from one to several swimlanes. Let\u0026rsquo;s assume that the \u0026ldquo;review\u0026rdquo; swimlane has a dedicated limit of three stories. When the third story gets in the lane the team should prioritize code reviewing these stories. Otherwise, no new stories can be propagated from \u0026ldquo;doing\u0026rdquo; to \u0026ldquo;review\u0026rdquo;. These stories will be reviewed and if the \u0026ldquo;delivered\u0026rdquo; column has a respective limit, they will also get deployed to production and eventually reach \u0026ldquo;done\u0026rdquo;, allowing space for more stories to be worked.\nThe application of the limit has not only made the problem apparent, but it has also provided a solution to it.\n# Fine-tuning the limits Assuming that some symptoms are visible and the team feels that some WIP limits would be helpful, a natural question would be how can a team go about setting them. What are the right the numbers? How many swimlanes should a limit span?\n# Avoid multitasking I would propose that the first thing to avoid is multitasking. A WIP limit greater than the number of software engineers in the team would mean that people are encouraged to multitask. For instance, imagine a team of five software engineers with a WIP limit of 6.\nKeep this in mind. In my opinion, if you are ready to set a WIP limit greater than the number of software engineers in the team, take a step back. Think the problem over again. Why do you want to do this? What do you expect to gain out of it?\n# Not too high Building on this point, a WIP limit equal to the number of software engineers in the team would mean that no one can multitask, but on the other hand, pairing and collaboration are not encouraged. This kind of beats the purpose, because fostering collaboration is a key motive for using this technique.\nThe two above-mentioned strategies can work but, only as first steps and only in rare situations. For instance, if some team members are very reluctant about using WIP limits and yet the rest of the team feels that they would be beneficial, perhaps it\u0026rsquo;s a decent first step. However, I see very limited benefits besides these cases.\n# But not too low either On the other hand, a very restrictive WIP limit can have negative effects. Not every task and story is suitable for pairing or requires more than one person working on it. Also, pairing is great, but, as discussed in extensively in my pair programming post, it can be exhaustive. Setting a WIP limit of two in a team with four software engineers would automatically mean that the engineers should always work in pairs to honour this rule. If this is what you are after - always working in pair - by all means, go for it. However, pay a lot of attention to it. Such a restrictive limit may lead to people feeling that they are suffocating or it may just be counterproductive.\n# Inspect and adapt Having said all these, we still haven\u0026rsquo;t answered the above-mentioned questions. Well, you might have guessed it. There is no right answer. There is no silver bullet. The very philosophy of Agile suggests a totally different approach to right answers and silver bullets. Scrum says \u0026ldquo;inspect and adapt\u0026rdquo;. That is what I would suggest.\nStart off with discussing the situation during the retrospective. Come up with the first iteration of a few WIP limits. Give it a go and watch what happens. Adjust it and repeat the process. This is an ever-ending-process. Keep shifting towards what works best for the team and always keep in mind that different things work on different teams.\n# Conclusion Being Agile means being after continuous improvement. This requires being able to read the symptoms and come up with experiments to help the team work better. Lack of focus, disrespect to priority, big bang releases and small bus factors are serious symptoms that should be dealt with.\nLimiting work-in-progress can provide a great boost to the team, like reducing the average lead time, improving collaboration, increasing the bus factor, identifying bottlenecks and more. If a team exhibits these symptoms, applying some WIP limits could be an experiment worth considering.\n","date":"2020-05-17T00:00:00Z","image":"//localhost:1313/img/posts/wip_limits.jpg","permalink":"//localhost:1313/limiting-work-in-progress-in-scrum/","title":"Limiting work in progress in scrum"},{"content":"Remote work has become an integral part of a number of professions, with software engineering being number one in the list. Working remotely requires a cultural foundation and a shift of mind on our perception. I believe that there is quite a lot of room for improvement on these points.\nSo, in this article I will share my thoughts and tips on points I consider important when running a remote retrospective. These come from the point of view of a scrum master. Regardless of whether people call themselves a \u0026ldquo;scrum master\u0026rdquo; or not, running a retrospective means wearing the hat, at least temporarily.\nMy intention here is not to cover the fundamentals, such as the goal and the structure of the session. These are covered extensively in my driving fruitful retrospectives post. My aim is to complement that post with the special case of a geographically distributed team.\nThroughout this post, I will be referring to a fully remote team. Apart from this and the colocated team, there is also a third case, in which some of the team members are working remotely and some in the same location. I will not be covering the latter in this post.\n# Engagement The primary goal of a scrum master remains the same whether the retrospective is taking place remotely or colocated. It is to make sure that all participants engage in the activity. This is a precondition. I cannot imagine a successful session that fails to meet this. When I drive retrospectives, this is the primary reason for which I use the \u0026ldquo;set the stage\u0026rdquo; step.\nWe will discuss a few extra points on this topic further below, on the facilitation part, but the reason that I am mentioning it here is that being remote imposes a few extra difficulties. So, before even starting the session, I would propose to focus on communication.\nWithout communication, there is no engagement and without engagement, there is no retrospective.\nTherefore I would propose to spend some time both during the preparation of the session and at the beginning of it to make sure that people can be seen, heard and understood.\n# Use the camera Using the camera is a great tip for remotely working teams. I find it particularly important during the retrospective. It feels very different conversing with just a voice than with an individual who is located somewhere else. Context and a great deal of expressivity derives from our body language. A lot of our reactions are expressed via it, using facial expressions or hand gestures, without verbal communication. Take a moment to think of how much volume of information is missed when listening to someone without seeing him.\nThese, missing pieces of information can make the difference between a constructive argument and one that leads to a dead end. These can also have a resounding effect on team bonding and chemistry in the long run. Personally, I always encourage geographically distributed teams to use their cameras as much as they can, but when it comes to the retrospective, I insist that everyone should use it.\n# Make sure everyone can be seen and heard Taking the time to make sure that everything is functioning properly before starting the retrospective is very important. Has everybody said something. Is everyone\u0026rsquo;s mic functioning as expected? Can everyone hear everybody else? Can everyone see everybody else? Ask yourself these questions before starting.\nThere is no point in starting a retrospective without resolving all sound and video problems. As a matter of fact, in case there is such a problem, the last thing the team wants is to be interrupted in the middle of an exercise to resolve a technical issue with somebody\u0026rsquo;s mic or camera. The last thing a participant wants is to contribute to the conversation only to find out, after a few seconds, that no one heard him.\n# Tools Being remote significantly restricts both the options on tools that can be used and the range of exercises that can be run. However, a wise choice on a collaboration tool and a careful selection of exercises can really boost the results of the session.\n# Use an online collaboration tool Retrospectives are all about interaction. The participants should come up with ideas and add information to the session. In order for the data to be meaningful, they should be gathered, processed and the team should work on them. During a colocated session, the wall or a board is naturally used. During a remote retrospective, I would strongly suggest to use an online collaboration tool. There is no point in suggesting a specific one, as there are loads out there that are free and can get the job done. Just make sure that a group of people can simultaneously work on the same space and that the data are updated in real-time (there is no need to refresh in order to see an update). In my experience, the more playful the tool is, the more the participants enjoy the session, so I would suggest something with a sticky-note-on-the-wall look and feel and lots of colours.\nWhat I would caution one against is not to use any tool and host a blank session, with the participants just discussing without any common ground to work on.\n# Reconsider the format Concerning the format of the session, I feel that there is a lot of room for experimentation. Generally, I like sticking to the 5 steps that I have thoroughly described in my driving fruitful retrospectives post, but there are quite a few factors that should be considered.\nSome exercises are not suitable for a team that is not colocated. For instance, there is no meaning running the park bench exercise on a remote session. The advantages of such an exercise derive from the mobility within the room, the high energy level and the playful format. I believe that attempting to run a variation of this exercise during a remote session would backfire. So, I would propose picking exercises that suite collaboration from distance.\nAlso, perhaps one might notice that an exercise takes considerably more time when performed remotely than when run on the spot. That\u0026rsquo;s reasonable as communication is harder and synchronization might require more time. I would suggest to always keep that in mind and, perhaps, adjust the session\u0026rsquo;s schedule.\n# Facilitation As far as facilitation is concerned most of the things that apply in colocated retrospectives, apply to remote ones too. Therefore, I will not repeat the thoughts that I have expressed in driving fruitful retrospectives (such as how to deal with silent members or members that dominate the conversation), but there are a few points worth discussing.\nThese thoughts assume that the facilitator is acting as a scrum master. The case the facilitator wears two hats, the one of the scrum master and the one of the member of the development team is outside of the scope of this blog post.\nI usually wear these two hats and I believe that driving a retrospective is perhaps the most challenging part of this dual role.\n# Make yourself invisible As always, try to make the team forget that you are even there. At all times, keep in mind that the scrum master is needed to help the team work meaningfully during the session. Try to be a servant leader. When needed, remind the team that you are not the protagonist.\nFor instance, I sometimes find that team members address me when commenting on sticky notes. This is a mini alarm for me. Usually, when I am physically present, I point to the rest of the team. This gets the job done and does not interrupt the team member. However, when being remote, I have no option but to interrupt her. It is one of the last things I want to do, but having someone addressing me is a signal I take very seriously. The retrospective is being derailed and I should take action.\nAs a second example, when team members are called to come up with input and \u0026ldquo;stick it to the wall\u0026rdquo;, they sometimes look for the facilitator to impose an order or the process. Take extra care to be \u0026ldquo;absent\u0026rdquo; at that point. This is easier to achieve when being remote. Just stay silent and let them self-organize. They will do it. Remember that silence is gold in this case. If it gets uncomfortable, just keep on staying silent. Someone will break the silence and the team will eventually function on its own.\nI could go on with a dozen examples, but I believe that the message is clear. Facilitate the session as a servant leader and fly below the radar as much as possible.\n# Consider breaking the ice Being physically present in a room follows that people have already talked to each other before the start of the session. Perhaps they just went out to get a cup of coffee or they were discussing in their offices, after the sprint review. However, this is obviously not the case in a remote session.\nKeep in mind that people need to feel comfortable before entering a session, let alone a retrospective. Breaking the ice can go a long way in this case. Instead of directly jumping to setting the stage and starting the retrospective, consider having some small talk first. Anything ranging from the weather and sports to the sprint review that just took place will do. Just make sure that people feel relaxed and ready to chat.\n# Make sure everyone contributes Every individual has a unique personality. Chances are that in a scrum team the spectrum of these personalities is going to be very broad. Naturally, some team members will open up more easily than others. However, it is crucial for the success of the retrospective to have everyone contributing. Unfortunately, it is easier for a closed person to \u0026ldquo;hide\u0026rdquo; and remain a spectator during a remote retrospective than during a colocated one. This is a problem that requires attention and very careful manoeuvring from the scrum master. Remember, that failing to address this can lead to losing a great part of the value of the session.\nInitially, make sure than during the set the stage step, everyone speaks and seems engaged and comfortable to contribute. Then, I would propose to choose the exercises very carefully. Prefer the ones that work in a round-robin fashion over the ones the require initiative form individuals. For instance, it is more likely to have everyone contributing in an I like - I wish kind of exercise, during which all members are required to speak at their own turn than in a 5-why analysis. During the latter, the same people could be asking and answering the questions throughout the whole exercise. Lastly, if nothing works and you notice that people remain passive, try to stimulate them. Ask them for their opinion on the matter or if they have something else to contribute that is not already heard.\nIn any case, this matter requires very delicate moves. Try hard not to be intrusive. When people feel judgement is being passed on them, they might feel offended and distance themselves even more. At all times, keep in mind that empathy is a key scrum master quality. Try to get into their shoes and do the best to help them and the team.\n# Follow-up After a fruitful session, a lot of ideas have been expressed and heard, a lot of discussions have taken place and a few action items have been produced as an outcome. It\u0026rsquo;s always a good idea to follow-up the session.\nPerhaps an email or even just a slack message will do. Just make sure that the retrospective is summarized and the action items are clear. This will create a sense of a completed work to the team and will emphasize the importance of following up on the work done during the retrospective. After all, the retrospective, apart from a summary of the sprint that just finished, is also the very last action on it.\n# Conclusion Running a retrospective for a geographically distributed team is very different from running one for a colocated team. However, with the proper care and organization, it can be as fruitful. Focusing on engagement is crucial for the success of the session. It\u0026rsquo;s easier for people to remain \u0026ldquo;hidden\u0026rdquo; when being remote and technical issues may add unexpected obstacles. A good real-time collaboration tool and a wise selection of exercises and format can be extremely beneficial to the outcome of the session. As in colocated sessions, facilitation is the key to a successful and fruitful retrospective.\n","date":"2020-04-05T00:00:00Z","image":"//localhost:1313/img/posts/remote_retrospectives.jpg","permalink":"//localhost:1313/running-remote-retrospectives/","title":"Running remote retrospectives"},{"content":"When was the last time that you did some pair programming? How often do you practice it and why? Is it actually pair programming or is it just two people sitting side by side?\nSoftware engineering is a young and rapidly moving profession. Things have changed radically over the past few decades and we have to realize that it is a team sport. Great software is produced by great teams and I cannot imagine a team being great without members that are interacting a lot.\nIn the following of this post, I will try to articulate my thoughts on pair programming, which I believe is an empowering practice and a skill that builds successful teams.\n# What is it Pair programming is an extreme programming (XP) practice. According to Kent Beck\u0026rsquo;s book, \u0026ldquo;Extreme Programming Explained: Embrace Change\u0026rdquo; it is\nA programming technique where two people program with one keyboard, one mouse, and one monitor\nSo, essentially, two software engineers, working on the same task, in a single machine. Two roles are defined and used by the participants, ideally swapped frequently: the driver and the navigator.\nThe driver is writing the code, focusing on the task in hand and in the micro view of the code. The navigator is constantly reviewing the code being written by the driver, is looking for logic problems and bugs and is thinking ahead of the architecture and design of the system, focusing on the macro view of the code. Now, having decided to pair, how do you go about doing it?\n# How to pair program Before thinking about roles and pieces of code, my advice is to focus on the setup. I find it critical that the screen is positioned in the center of the desk and both participants have equal access to it. Otherwise, you are running the risk of creating a situation in which one participant feels like a \u0026ldquo;guest\u0026rdquo; in the other\u0026rsquo;s office, instead of an equal collaborator.\nHaving taken care of the screen\u0026rsquo;s position, the second most important point, in my opinion, is having two keyboards, if possible. This contradicts the above-mentioned definition of pair programming, which talks about one keyboard, but I believe it is very important to remove the psychological barrier of actually having to \u0026ldquo;grab\u0026rdquo; the keyboard to contribute one line of code when needed.\nWith the setup in place, let\u0026rsquo;s focus on the process. I would suggest making sure that you swap roles frequently. This ensures that both participants stay engaged and focused and that their minds work on both the micro and macro view of the code. Having the same driver for a lot of time can end up with the navigator feeling marginalized and disengaged. There is no \u0026ldquo;right\u0026rdquo; amount of time, but, out of personal experience, I would suggest swapping every few minutes. Of course, this is totally subjective and the pair should experiment and find what works best for it.\nStaying in the context of role swapping, when using Test Driven Development (TDD), I have found extremely useful the \u0026ldquo;ping pong\u0026rdquo; technique. According to this, the driver writes a failing unit test. Then, roles are swapped and the new driver makes it pass and writes the next failing unit test. Then, roles are swapped again and so on and so forth. This technique creates pace and ensures frequent role swaps.\nApart from roles, make sure to also switch pairs frequently. In case the whole team is pairing amongst themselves, perhaps it could be a daily scrum discussion. I\u0026rsquo;ve heard of teams, which pair by default, that apply a soft and hard swaps a couple of times throughout the week. So, for instance, every Monday, there is a soft swap and people are free to either continue pairing with their colleague or swap to work on another task or with someone else and every Wednesday there is a hard swap, in which people actually have to switch pairs. No matter which method you use, I would suggest making sure that pairs are rotated frequently.\nArguably, the best results out of pair programming come when people of the same level and expertise work together (for instance novice-novice or expert-expert). However, I would encourage you to also try mixing it up a bit and have expert - novice pairs. In this case, pay extra attention to not having the expert driving a lot! If anything, make sure that the novice is driving more, otherwise, you may end up with the novice watching the expert programming, getting lost and giving up soon. Also, an expert may be particularly unwilling to pair with a novice, believing that it will slow her down. It will! but always remember that\nPair programming may slow the expert down for a few hours, but it will speed the novice up for the rest of her life\n# Why bother Now, the first reaction of people that have not used the practice is scepticism, to say the least. After all, it sounds very counter-intuitive at first. Why have two people doing the work that one of them would originally do anyway? So, let\u0026rsquo;s talk a little bit about the benefits of pair programming.\n# The sum is greater than the parts Pair programming is a powerful technique when you need to tackle a very difficult problem. The reason is that, empirically, the quality of the work that is being produced by the pair is higher than the one of the work that each team member would produce on her own. I know that it sounds strange and is indeed very counter-intuitive, but, surprisingly, I have found it to be true every single time that I have paired on a difficult task. When done right, the level of concentration is unprecedented and two minds, deeply focusing on the same problem, can produce extremely high-quality work.\n# Collective code ownership The more a team is practicing pair programming, the more it increases collective code ownership. When an individual writes a piece of code and then the team reviews it, inevitably, the author is implicitly perceived as the \u0026ldquo;owner\u0026rdquo; of this piece of code. Apart from increased collective code ownership, which is a vital quality for an agile team, pairing defaults the bus factor to 2.\n# Code is reviewed automatically One of the greater benefits of pair programming is that the code is reviewed automatically, as it gets constantly reviewed by the navigator while is being typed by the driver. Taking into consideration that roles are swapped frequently, essentially the code is reviewed by the pair. Additionally, it is reviewed in a more active way, driven by conversation and modifications, instead of passively and silently reading a pull request without the author of the code being present to initiate a conversation. As a matter of fact, it is so well reviewed that it can be checked in and merged right away, although I would advise against it and I would propose to open a pull request, have the rest of team have a look at it as well as have the pair take a more distant look after the work is done.\n# Increased collaboration Gone are the days that software was produced by individual sitting in their cubicles, working as isolated as possible. Nowadays, it is well understood that great software is delivered by great teams. Therefore, we focus our energy a lot into building great teams. Honestly, I can\u0026rsquo;t think of a more catalytic action to this than having two people working together, on the same problem. Personally, as a scrum master, I always encouraged the team to work in pairs as much as they can.\n# Learning opportunity People say that code reviews are a great learning opportunity. I can\u0026rsquo;t even begin to describe what a wonderful learning opportunity pair programming is. Honestly, I don\u0026rsquo;t remember pairing without sharing knowledge. Sometimes sharing great software design ideas. Sometimes learning a keyboard shortcut or a small IDE feature. There\u0026rsquo;s always knowledge sharing during pair programming.\n# More difficult to cut corners We do get tired when writing code. Especially, when solving hard problems. These are the moments when we get more prone to cutting corners. \u0026ldquo;Let\u0026rsquo;s skip this unit test\u0026rdquo;. \u0026ldquo;I could improve this, but let\u0026rsquo;s leave it like this for now and I\u0026rsquo;ll refactor in the future\u0026rdquo;. We\u0026rsquo;ve all been there and it is quite natural when we grow really tired. We still know the right thing to do, but we lack the discipline to do it at this given moment. When working in pairs, cutting corners is more difficult. Usually, either the navigator will \u0026ldquo;push\u0026rdquo; towards the right direction or the driver will feel less at liberty to opt for a dirty solution.\n# Less distractions A software engineer works focused on a task, having built a mental diagram and his colleague asks \u0026ldquo;have you had lunch?\u0026rdquo;. Suddenly, the mental diagram is gone and 15 minutes are required to reconstruct it. Sounds familiar? Writing code requires extreme concentration and we all know that interrupting a software engineer while writing code is a huge \u0026ldquo;no-no\u0026rdquo; (especially when wearing headphones). Fortunately, working in pairs decreases interruptions a lot. People usually think twice before interrupting a pair.\n# Onboard a new team member Do you remember your last onboarding-a-company experience? How long did it take you to become fully enabled and how did you go about achieving it? Personally, I believe that working on a task and asking questions when stuck is a suboptimal approach. I find that pairing with a teammate is an excellent onboarding technique. As a matter of fact, I believe that pair programming is tailored made for onboarding new members. knowledge sharing is flowing in an unprecedented pace (both domain/business and technical) and there\u0026rsquo;s also a deliverable coming out of the process.\n# When to pair Of course, as with most practices, pair programming is not a silver bullet and we should be cautious when or for how long we practice it. As I mentioned above, there are teams out there that pair by default. There are also teams that pair only when no individual can solve the problem on her own. I personally feel that there are limits and each individual (and team) has to know when to pair and for how long to pair. Don\u0026rsquo;t get me wrong. Perhaps always pairing is what works for you. I just argue that this is not the case for everyone. So, I would suggest to feel free to pair at any given moment, but try hard to pair in the following situations:\nSolving mission-critical or hard problems: I always feel that the most sensible case of choosing to pair is when tackling a very difficult problem or a mission-critical task. The quality of the code will rise, the number of defects will drop and, - arguably - most importantly, it will create/increase collective code ownership. Personally, as a rule, I try to pair in such situations and more often than not, I have seen it pay off. Retrospectively, I feel that any result I could produce would be inferior to the one we produced with my pair. Also, when something breaks in this, mission-critical piece of code, there are at least two people that are very familiar with it and can modify it fearlessly.\nMaking architectural/design decisions: There are tasks that require making architectural or design decisions. Perhaps they are fairly simple or perhaps, after making these decisions, finishing the implementation is straightforward. I would encourage you to pair when working on such tasks. Architectural and design decisions are very important in a software project and having two minds working on them is preferable to having just one. This will help you engage in a dialogue and weigh different alternatives instead of going with the first idea or not challenging a decision, both of which are common cases when working on our own. Additionally, at least two people will be familiar with these, important decisions.\nWhile knowing when it to pair is important, we should also know when not to pair. So, I would discourage pairing when solving trivial problems. If you find yourself having to change a configuration or implement a fairly simple feature, that barely requires any design at all, pairing would be an overkill in my opinion. This is because there would be no important decisions to be made or serious hurdles to overcome and putting two minds in this problems just seems wasteful to me.\n# How much should we pair for So, knowing when to pair is important, exactly as is knowing when to stop. Allow me to stress once more that there are no rules on these matters and I strongly feel that conclusions should be drawn empirically and always remain open to adjustments as the team matures. Therefore, below I outline my personal findings.\nSomething to always keep in mind is that writing code in pairs is exhausting. It requires a tremendous level of concentration, exactly like individual programming does, plus a lot of energy devoted to interacting with your partner. After a few hours of pairing, it grows increasingly harder to keep producing high-quality work, which is the goal after all. So, I have come to believe that I should stop pairing when I feel like this. For me, this usually means that I should not pair for more than a few hours a day. However, this conclusion is totally empirical. Once again, there are teams out there that pair by default. So, I would strongly recommend that each team (or pair) experiments until it finds its balance and that best works for it.\nIf you do practice pair programming though, I would suggest that you do it on a frequent basis, every day if possible.\n# Pairing remotely Remote work has evolved in an integral part of software engineering teams. I used to think that pair programming would be very difficult (if not impossible) to do when the team members do not share the same physical space. After all, this technique is heavily based on the benefits of direct communication and interaction. I recently gave it a try nonetheless, and the results were remarkable. Not only it worked, but the outcome was of excellent quality.\nRetrospectively, I gave it some thought and tried to understand why it worked in such a great way. I realized, that neither communication nor interaction is negatively affected when using modern technology in the right way. Online call and remote control tools allow us to work seamlessly on the same machine. Besides, each participant is comfortably sitting before her dedicated screen and keyboard, without even feeling that her personal space is invaded, which might be the case when first adopting pair programming in person.\nI would strongly recommend to give remote pair programming a go and the results might astound you, just as they did me.\n# Challenges As with every new practice, there are going to be hurdles to overcome when adopting it. Below, I have outlined the ones, which I think are the most common ones and my suggested approaches to tackle them.\nResistance: People are resistant to change. That\u0026rsquo;s a fact. It is natural (actually it is the definition of \u0026ldquo;inertia\u0026rdquo;). Software engineers that are not practicing pair programming are going to be sceptical when it comes to adopting it. In my experience, it is even harder than making them write tests - or write tests first - since it involves the natural discomfort of entering their personal space. Also, people are going to be afraid of lower efficiency. I am not in favor of persuading people for anything. I would suggest to propose them to pair on a simple task, just to see what it looks like and perhaps briefly present the benefits of the technique. If this doesn\u0026rsquo;t work, try to lure them. For instance, ask a teammate for her assistance, ask her to write it down on your machine. Maybe grab the keyboard to contribute and give it back to her, asking for some more guidance. If this doesn\u0026rsquo;t work either, perhaps not going any further for the moment being would be the best choice.\nDisengagement: One of the biggest pitfalls to watch out for is a disengaged pair. Usually, this means that instead of working together, the pair just works side by side. A common symptom is a navigator who is not paying attention to what the driver types and is not playing an active part in the process. This kind of behavior totally defeats the purpose and should be avoided by all means. If you find yourself in this situation, I would suggest to ask your partner if she needs a short break or if she desires to stop pairing altogether for the time being.\nLack of communication: Always remember that the key in pair programming is communication. This is what makes the sum greater than the parts and this is what drives everything throughout the whole process. So, make sure that you embrace communication at all times when pairing. If you realize that you are not communicating and interacting enough with your partner, try to stimulate it. Think out loud, contemplate on decisions that you make, ask questions and try to keep the feedback between the two of you flowing at all times. When you feel that you don\u0026rsquo;t have the energy for this, take a short break, or stop pairing for the moment being. After all, if there isn\u0026rsquo;t enough energy for communication, how can there be enough energy to produce high-quality software?\n# Conclusion Pair programming is a truly powerful technique. It brings high-quality results, increased levels of collaboration, collective code ownership and loads of other benefits. Studying the technique is important in order to apply it correctly to gain all these benefits. As responsible, professional software engineers, we should empirically find out when of for how long to use it in order to maximize the advantages for our team. Working remotely not only does not hinder pair programming but, with the right tools, it can leverage the merits. Finally, don\u0026rsquo;t be discouraged by challenges. As always, they will present themselves, but they can be overcome.\n","date":"2019-12-15T00:00:00Z","image":"//localhost:1313/img/posts/pair_programming.jpg","permalink":"//localhost:1313/pair-programming-making-the-whole-greater-than-the-sum-of-its-parts/","title":"Pair programming: making the whole greater than the sum of its parts"},{"content":"Lambda expressions are powerful and allow us to write concise, elegant, declarative code. A lot of people has already adopted them, mainly leveraging the power of streams in iterations, but lambda\u0026rsquo;s toolkit is far richer than that. This is why I decided to write this blog post and explore some aspects of how lambda expressions can prove useful in software design.\nWe will do this exploration via a real world case study in order to demonstrate how we can apply these principles in our everyday work.\n# The case study Instead of creating a new case study, from scratch, I decided to extend the one from my previous blog post, in which we examined closely the problem of input validation. We assumed an android application that displays a form and we came up with a robust solution to validate the input of this form (leaving out android specifics on purpose and simplifying a bit to put emphasis on the right parts).\nThe key takeaway was that after drafting a first, working version of the code, we refactored our way to a much better crafted one. We applied the Open-Closed Principle so that we could extend the behavior of our validation module (e.g. add validation for new fields, such as a postcode field) without having to modify our existing validation code. In this way, we improved the design of our solution by making the code less fragile and therefore more maintainable.\n# Room for improvement However, in software, there is no such thing as a perfect design and there never will be. There will always be things to improve. As responsible, professional software craftspeople, we should always study the pros and cons of our solutions and know their weaknesses and limitations and, as I always like to say, work the trade-offs.\nConsidering the solution of the previous post, there is definitely room for improvement. First of all, as already mentioned in that post, we should apply the Dependency Inversion Principle to invert the dependencies between the ValidationService and EmailValidator and PhoneValidator (currently there is a transitive dependency between them, while the former should not know about the latter). A second point of interest is the life cycle of the ViewValidator object that we create. Please remember that we designed it to be used like this:\nformViews.forEach(view -\u0026gt; { ViewValidator validator = ViewValidatorFactory.makeFor(view); validator.validate(view.getText()); }); Allow me to refresh our memory on a few basic points for this case study. We assumed that we have a list of View objects (in android all UI elements derive from View) and that all these objects have a tag, which we can retrieve using a getter, denoting the view’s input type (e.g. Email or Phone) and a getter to retrieve the text of the view.\nIn this case we create a new instance of ViewValidator for every view that we wish to validate. However, this does not come naturally from the design of the class. We do not know it. We simply assumed it. And these kind of assumptions can lead to a great deal of problems down the road. What if we have a bunch of similar views to validate (e.g. 3 e-mail fields)? Should we use the same instance for all 3 of them or is this instance disposable and we should create a fresh one for each validation? Well, the answer is that there is no way to know (unless, of course, we open the ViewValidator source code and have a look ourselves). The design of the class does not communicate its intent as far as the life cycle of the object is concerned.\nThis is clearly an issue that could - and perhaps should - be addressed. Thinking carefully about the architecture of the system (its design on a macro level) is essential, but taking the time to think through our micro level design (e.g. class design) is equally important.\n# The loan pattern Thankfully, there is a design pattern, which solves exactly this problem, in a very elegant way and its name is the loan pattern. I first came across it while reading Venkat Subramaniam\u0026rsquo;s excellent book Functional Programming in Java. Venkat does a wonderful job explaining this pattern as it naturally emerges while refactoring a real world piece of code and I suggest that you read it (see section \u0026ldquo;Creating Fluent Interfaces Using Lambda Expressions\u0026rdquo;), but I will try to explain the basic points myself here.\nEssentially, the pattern removes the responsibility of dealing with the object\u0026rsquo;s life cycle from the function that uses it. Instead, this responsibility lies with the class itself. In order to achieve this, we create a resource and pass it to the function. As soon as the function terminates, the resource is destroyed.\nIn our case, to achieve this, we would ideally want to write something like this (remember that tags is what will be used to determine the type of validation that should be applied and value is the value that is to be validated)\nValidator.validate( validator -\u0026gt; validator.withTags(\u0026#34;email\u0026#34;).withValue(\u0026#34;someone@example.com\u0026#34;) ); The point is that whoever uses this piece of code does not have to worry about the life cycle of the Validator object. An instance will be passed as an argument and destroyed as soon as the validate() function terminates. This is where the name comes from. The Validator object is loaned to the function.\nThis is an incredibly smart and elegant solution to a very sneaky problem. Lambda expressions empower us to implement it. Let\u0026rsquo;s dive into the implementation.\n# Applying the loan pattern Assuming that the Validator class is to be used as stated above, the obvious challenge would be to come up with a way to make use of the loaned resource in the validate() function. This can be easily achieved with the Consumer functional interface (java.util.function.Consumer), which is designed to accept an object and execute a piece of code on it. So, redesigning our Validator class like the following, would do the job.\npublic class Validator { private static String COMMA = \u0026#34;,\u0026#34;; private String tags; private String value; private Validator() { } public Validator withTags(final String tags) { this.tags = tags; return this; } public Validator withValue(final String value) { this.value = value; return this; } public static List\u0026lt;Violation\u0026gt; validate(final Consumer\u0026lt;Validator\u0026gt; block) { final Validator validator = new Validator(); block.accept(validator); return validator.applyValidations(); } private List\u0026lt;Violation\u0026gt; applyValidations() { return Arrays.stream(tags.split(COMMA)) .map(this::validationFor) .map(validation -\u0026gt; validation.applyTo(value)) .flatMap(List::stream) .collect(Collectors.toList()); } private Validation validationFor(final String tag) { switch (tag) { case \u0026#34;Email\u0026#34;: return new EmailValidation(); case \u0026#34;Phone\u0026#34;: return new PhoneValidation(); default: return new DefaultValidation(); } } } There\u0026rsquo;s a lot of things to notice in this class, so let\u0026rsquo;s take them one by one.\nFirst, the validate() function, does exactly what we discussed earlier. It accepts a piece of code meant to be executed in an instance of Validator. It creates this instance and executes this piece of code on it. This serves in \u0026ldquo;configuring\u0026rdquo; the object with the right tags and value. Then, it applies the appropriate validations. Notice that we also made the constructor private, essentially disallowing direct instantiation and explicitly removing the burden of this responsibility from the caller. We make sure that no one will instantiate this class (other than the validate() function of course). The withTags() and withValue() functions act as builder functions that allow us to chain our calls.\nSecondly, instead of an explicit factory class to create specific Validation objects based on the tags, we achieve this in the validationFor() factory method. This has the extra benefit of encapsulating the Validation polymorphic instantiation logic in the Validator class, which is the only one that needs to know about it anyway. The various Validation derivatives (EmailValidation, PhoneValidation etc) are implementation details and are subject to change at any time. No one should depend on them.\nFinally, the applyValidations() function pretty much does what the client in the previous version was doing. It splits the tags of the view and creates an appropriate Validation for each tag. Then it applies this validation to the value and finally, it flattens all the violations in a single list to return it. Usage of lambda expressions makes this function declarative, elegant and very readable.\nBelow is the Validation interface\npublic interface Validation { List\u0026lt;Violation\u0026gt; applyTo(final String value); } and its three derivatives\npublic class EmailValidation implements Validation { @Override public List\u0026lt;Violation\u0026gt; applyTo(final String value) { // Actual email validation code omitted for brevity return Arrays.asList(); } } public class PhoneValidation implements Validation { @Override public List\u0026lt;Violation\u0026gt; applyTo(final String value) { // Actual phone validation code omitted for brevity return Arrays.asList(); } } public class DefaultValidation implements Validation { @Override public List\u0026lt;Violation\u0026gt; applyTo(final String value) { return Arrays.asList(); } } That\u0026rsquo;s it. We have implemented the loan pattern.\n# Retrospective So, by this point you might be wondering if it is worthwhile to go through all this refactoring. Let\u0026rsquo;s take a step back and examine what we have achieved.\nFirst of all, the we still comply to the Open-Closed principle and therefore we can extend the module\u0026rsquo;s behavior without modifying existing code.\nAdditionally, the responsibility of the life cycle of the Validator object does not lie with the caller, but we have already taken care of it.\nFurthermore, what\u0026rsquo;s really important - and unfortunately seriously underestimated - is that the design communicates this decision.\nFinally, an additional advantage is that Validation instantiation logic is encapsulated in the Validator class, along with the rest of its implementation details.\nAs far as the form validation case study is concerned, it might worth it or it might not. To be honest, it doesn\u0026rsquo;t matter. I did take the trouble to do exactly this refactor (except in Kotlin) the first time that I had to enhance our validation feature after having read Venkat\u0026rsquo;s book, but that is up to each one of us. Once again, as software craftspeople it\u0026rsquo;s us that should work the trade-offs everyday and make the call. In any case, the key point is that we can use functional interfaces and lambda expressions to produce elegant and robust software designs.\n# Conclusion Lambda expressions allow us to write concise and declarative code, but they offer way more than that. They can be used as a design tool. High order functions (functions that take functions as arguments) are a game changer and they can fundamentally alter our perceptions on architecture, design patterns and software design.\nRefactoring to transfer the responsibility of managing a resource\u0026rsquo; s life cycle from the caller to the callee may be worthwhile or not, depending on the problem in hand. It is important knowing that we have the option and being able to make a call on a per case basis.\n","date":"2019-09-01T00:00:00Z","image":"//localhost:1313/img/posts/software_design_with_lambda_expressions.jpg","permalink":"//localhost:1313/software-design-with-lambda-expressions/","title":"Software design with lambda expressions"},{"content":"Have you ever come across of big ball of mud in the system that you work on? Have you ever wondered how it ended up like this? I bet that no one gets up in the morning and thinks \u0026ldquo;I will get to work to create a huge mess today\u0026rdquo;. However, there was at least one huge mess in the majority of the software projects I have worked on. What causes this?\nA typical scenario is that a piece of code starts off simple and innocent, but we always have to keep in mind the bigger picture. The architecture of the system. The code design. It is an integral part of our day to day work. Failing to pay attention to it, can start a chain reaction. One that leads to a big ball of mud.\nLet\u0026rsquo;s use a simple case from a real world project and study the risks that we introduce by not thinking ahead and designing the code carefully.\n# A case study Instead of creating an example around trivial, overused, fictitious domains, consisting of either shapes or animals, I believe that a real case will enable us to apply the principles to a professional context, which is key to a better understanding. This is why I chose to focus on a problem that I faced a while ago on work. Of course, I have simplified it quite a lot in order to remove noise and focus on the essential parts.\n# The problem Let\u0026rsquo;s assume that we work on an android application and the task in hand is the validation of a form, which the user should fill in. So, the form may contain fields for the user to fill in her name, phone, e-mail address, age, gender etc and before processing the information, we should validate that it is correct. In some cases validation may be redundant with the use of the appropriate UI elements (for instance, we should not validate gender if we use a radio button for it), but for some other cases (e.g. e-mail or phone number) we should definitely validate the user input.\nFor the sake of simplicity, we will not occupy ourselves at all with android, the UI and the way that we collect the data. We assume that we already have a list of View objects (in android all UI elements derive from View). We further assume that all these objects have a tag, which we can retrieve using a getter, denoting the view\u0026rsquo;s input type (e.g. Email or Phone) and a getter to retrieve the text of the view (in reality things are a bit more complicated, but we make these assumptions because the point of this post is not to delve into android UI details).\nTherefore, all we have to do is to implement a module that receives this list of View objects and validates the input data that they hold.\n# A first implementation This sounds like a reasonably straightforward task and agile teaches us that we should go with the simplest thing working. Therefore, a first implementation of the solution could look like the following:\nfor (View view : formViews) { if (view.getTag() == \u0026#34;Email\u0026#34;) // Apply email validation logic else if (view.getTag() == \u0026#34;Phone\u0026#34;) // Apply phone validation logic } Now, this is a very succint piece of code and if we care enough to extract some methods for the if block conditions, it could even be readable and retain the same level of abstraction.\nHowever, there are things that we should be dissatisfied with. Feel free to take some time to reflect before continue reading. Which could these issues be? What troubles you with this piece of code?\n# Architecture Let\u0026rsquo;s not fool ourselves, we\u0026rsquo;ve all written code like this (at least I know that I have), but as we grow more experienced, we should identify shortcomings and take the pains to address them.\nApart from some minor issues, like the fact that we should extract some constants from these magic strings and the ones that we mentioned above (extracting methods for the the if block conditions etc), which are easy to amend and would not cost that much in the long run even if we neglected them, there is a serious concern in this piece of code.\nLet\u0026rsquo;s think for a moment what would happen if a new field was added to the form. A field which did not exist before and therefore for which we hadn\u0026rsquo;t implemented any validation logic. Say a postcode field. How would we add support for this new field in our existing code?\nMost probably we would add an extra else if block to handle the case of the postcode. However, that means that we would be modifying the existing code to add an extra feature. This sounds like an oxymoron, doesn\u0026rsquo;t it? When we want to add a new feature, we should add some code and not modify the existing code.\nOf course, this case is simple and I bet you think \u0026ldquo;what could possibly go wrong with adding an extra else if block?\u0026rdquo;, but as we keep on adding more and more conditionals when requested to add a new field to a form, the code could grow quite complex. There could be functions that are used by more than one case, or even worse, there could be shared state. Perhaps we could reach to a point that by making a modification for one case, we accidentally break another case. According to Uncle Bob, that is a sign of great significance. The system is exhibiting the symptom of fragility.\nAdding support for a new feature and accidentally breaking an unrelated feature is a dreaded situation. As software craftspeople, we should go to great lengths to avoid it. Therefore, let\u0026rsquo;s examine how we could shield our code from such problems.\n# The Open-Closed Principle The Open-Closed principle (OCP) is the O of Uncle Bob\u0026rsquo;s SOLID principles (described in detail in Clean Architecture). As formulated by Bertrand Meyer in Object Oriented Software Construction, it states that\nA software artifact should be open for extension but closed for modification.\nContradictory as it may sound, there\u0026rsquo;s a lot of wisdom in that sentence. Essentially, we should be able to extend the behavior of a module, without having to actually modify its code. That resembles a lot what we discussed earlier. When we want to add a feature (behavior), we should add some code instead of modifying the existing code.\nSince this is a notoriously difficult to understand principle (perhaps due to the contradiction when articulated), let\u0026rsquo;s apply it to the input validation problem, that we analyzed earlier.\n# OCP compliant validation Let\u0026rsquo;s keep in mind that the goal is to implement a validation module that can be extended without being modified. Let\u0026rsquo;s try to design it in such a way that implementing the postcode validation cannot affect the existing validation logic.\nIn order to achieve this, we should separate the high-level validation policy from the low level details. The former refers to the way we validate a set of data and the latter to the details of how we validate data for specific input fields (like e-mail, phone numbers and postcodes). Ideally, we would like the former to be agnostic to the latter, like the following:\nformViews.forEach(view -\u0026gt; { ViewValidator validator = ViewValidatorFactory.makeFor(view); validator.validate(view.getText()); }); This reads like a nice algorithm. For every view, we get hold of an appropriate validator and apply its validate() method to the text that the view holds. Notice that we do not know how each specific field get validated. This is achieved by getting a Validator on runtime using the ViewValidatorFactory, but not knowing on compile time which one we will get on runtime. To achieve this, we need to create an interface like the following and have the factory returning objects deriving from this interface\npublic interface ViewValidator { void validate(String input) throws ValidationException; } and implement it for every specific field that we need to validate, as follows\npublic class EmailValidator implements ViewValidator { public void validate(String input) throws ValidationException { // Actual email validation code omitted for brevity } } and\npublic class PhoneValidator implements ViewValidator { public void validate(String input) throws ValidationException { // Actual phone validation code omitted for brevity } } Now, all that\u0026rsquo;s left to glue it all together is to implement the factory that creates the validators based on the view.\npublic class ViewValidatorFactory { public ViewValidator makeFor(View view) { switch (view.getTag()) { case \u0026#34;Email\u0026#34;: return new EmailValidator(); case \u0026#34;Phone\u0026#34;: return new PhoneValidator(); default: return new DefaultValidator(); } } } This design is depicted below, in figure 1.1.\nFigure 1.1: Validation compliant to the Open-Closed Principle\nThe ValidationService has a transitive dependency to the EmailValidator and PhoneValidator (which is a shortcoming that we should amend using an abstract factory to apply the Dependency Inversion Principle) and therefore will be recompiled when we add a PostcodeValidator, but other than that (which is harmless unless we have an architectural boundary between the two modules) the source code of the ValidationService and the rest of the validators will remain untouched, which means that we have solved the fragility issue, by provisioning for the addition of new fields (and therefore validation logic for them) in the future. In other words, there is no way to break the functionality of (e.g.) the EmailValidator by adding a PostcodeValidator.\nIndeed, Let\u0026rsquo;s consider what is needed to add validation for the postcode now. All we have to do is to create a new derivative of the ViewValidator, the PostcodeValidator and apply a minimal modification to the factory, to be able to create one for the appropriate view. The change is depicted in figure 1.2, denoted with dotted rectangles and arrows.\nFigure 1.2: Adding a postcode validator to the existing implementation\nIn this way, we manage to extend the behavior of ValidationService without modifying it.\n# Iterative approach Of course, presenting the code in its final state, like I did, may lead to a reasonable question. Did it just pop magically into my mind? What if I can\u0026rsquo;t think of the big picture all in once?\nAs a matter of fact, that is neither the way I wrote it, nor the way I would consult anyone to go about writing it. On the contrary, I used an iterative approach. I started with a suite of tests that led me to the first implementation. Then I identified the problems and I felt dissatisfied with the implementation, which led me to refactoring. I used the suite of tests as a safety net and I started applying small modifications to the structure of the code, making sure that I did not break the tests after every such modification. With every change, I amended something, which got me closer to what I had in mind as a goal (an open-closed validation module).\nThere is no need to think of everything upfront. In fact, there is no need to think of anything upfront. Just get a working piece of code, as simply as you can, but don\u0026rsquo;t stop there. Don\u0026rsquo;t be satisfied with it. Study it. Identify weaknesses and strengths and refactor to make it better. Refactoring is a mighty tool in our software design arsenal. Use it to shape the code the way a software craftsperson would.\n# Conclusion Implementing a solution to a problem can be easy, especially for a relatively simple problem. What is hard is to distance ourselves from our solution and improve it. However, as software craftspeople, we should train ourselves to identifying downsides and merits of architectures and code design decisions and even more importantly, take pains to address them.\nViolating the Open-Closed Principle may seem harmless, but as the code base grows it can turn out to be an insurmountable obstacle to the project\u0026rsquo;s sustainability. There is no such thing as a perfect architecture, that can shield our code from every potential future change, but provisioning for reasonable changes and structuring the code respectively is part of our job, rather than nice-to-have.\n","date":"2019-07-14T00:00:00Z","image":"//localhost:1313/img/posts/open_closed.jpg","permalink":"//localhost:1313/open-closed-principle-a-case-study/","title":"Open-Closed principle: a case study"},{"content":"A few days ago, right after my talk/demo on hands-on Test Driven Development (TDD) on the JHUG meetup, I noticed that a lot of conversation was about applying TDD in real world systems. Somehow people felt that it was great for a short demo or for implementing a small, algorithmic piece of code, but could not see how it could be applied to a greater scale.\nConversation quickly shifted to Outside-In TDD and I decided to try and organize my thoughts concerning the two approaches. Timing couldn\u0026rsquo;t be better. Having just finished watching an exceptionally good clean coders series on the comparison between the two TDD styles, I had already decided to blog about it.\nTherefore, after giving a very brief overview of the two approaches, I will attempt to describe their strengths and weaknesses according to my opinion.\n# Overview of the techniques There is no way I can thoroughly describe the two approaches in such a short post, but this isn\u0026rsquo;t the intention here anyway. However, I feel that a very brief overview would facilitate in understanding the points that I am about to make. There is plenty of sources online explaining in detail both techniques, so please, feel free to consult them prior to continuing if needed.\n# Classicist (Chicago school) Classicist TDD requires that we lock ourselves in the red-green-refactor cycle, pushing requirements in the form of failing unit tests (red), implementing an increment to fulfill these requirements (green) and then working on structuring the code in a better way (refactor).\nThis approach attempts to minimize mocking and most of the design happens at the refactor step, having already implemented a working increment.\n# Outside-In (London school) Outside-In TDD uses a different approach. An extra step is inserted in the TDD cycle, the one of writing a failing acceptance test. So, we first focus on writing a failing acceptance test and then on locking ourselves in the above mentioned TDD cycle, for every class needed, until the requirement of this acceptance test is fulfilled. Focusing on one acceptance test at a time, we TDD our way from the outmost layer of the system (controller, queue consumer etc) all the way to the core (domain, database layer etc).\nSome principal differences with regard to the previous approach are that mocking and stubbing are heavily used and most of the design decisions are made in the red state, allowing for more minor adjustments in the refactor step.\n# Where I stand It is reasonable for one to wonder whether I am biased on the topic or not. So, please allow me to clarify it before I proceed.\nIn my early TDD steps, I was mainly influenced by Uncle Bob and therefore, I started off as a classicist TDDer. After a considerably big learning curve, I started to like TDD a lot, but I was not thrilled by it. I always felt that the technique was great, but its professional application was limited and the benefits not always tangible (at least in my mind).\nThis changed radically the day I attended Sandro Mancuso\u0026rsquo;s excellent \u0026ldquo;Crafted design\u0026rdquo; workshop. Despite my obvious shortcomings during the workshop, I loved the idea and I followed up hard and persisted until I was able to apply Outside-In TDD professionally and eventually transfer knowledge within my company and influence colleagues. I was finally thrilled and enthusiastic about applying TDD professionally and, frankly, ever since I did, I find it very hard to work in a different way. So, this is where I stand. I love Outside-In TDD.\nHaving said that, I have come forward with my bias before delving into the topic on purpose. I wanted to state where I stand and clarify that I will not let it impede my judgement.\n# Comparison Let me start by clarifying that the two TDD styles are not mutually exclusive. A skilled software engineer should ideally switch between the two, adapting to the situation in hand. However, I do feel that there are considerable strengths and weaknesses in each one and to the analysis of these is where I will focus for the rest of this post.\n# Classicist # Strengths # Enables refactoring through loose coupling and contra-variant structure An undeniable, powerful advantage of classicist TDD is that tests are loosely coupled to production code. The lack of mocking (and therefore stubbing) leaves the tests with a minimum amount of knowledge of how is the production code achieving what it needs to achieve. This enables even bold refactorings, using the unit tests as a safety net throughout the process. After all, as already mentioned above, important design decisions are made in the refactor step in this approach.\nThis refactoring ability is enhanced by the contra-variant structure of the code. Instead of having a test class per production class, the two structures are independent. This is achieved by testing public APIs, letting implementation details hide behind these APIs. This empowers refactoring even more, as even serious refactoring moves (like deleting whole classes for instance) would most likely not lead to broken tests.\nRemember that during refactoring we want a steady, fast-executing suite of tests to verify after every refactoring move that we indeed only changed the structure of the code and not its behavior. I have articulated my arguments on this on my \u0026ldquo;test behavior\u0026rdquo; post\n# Delayed design decisions Another strong quality of the classicist TDD that I like a lot is that design decisions are delayed as much as possible (if only we all did more of this). This follows logically from the fact that we first make it work (red to green) and then we think about how to make it better, doing most of the design in the refactor step, as stated more than once earlier. Delaying design decisions is one of the qualities that makes us truly agile (as opposed to lots of sticky notes, but that is another post once again - see agile code).\n# Evolutionary design In the classicist approach we start off small in terms of design and as we grow the code base to accommodate more requirements, we continuously refactor the code to adjust the design. This line of thought complements the delayed design decisions characteristic and binds excellently to the agile mindset. Together, they embrace the YAGNI principle and therefore, premature design decisions and over-engineered solutions are avoided. Instead, at any given moment, the design reflects the current needs of the application.\n# Weaknesses # Reduced test readability I am a big fan of the triple A rule (Arrange-Act-Assert) and part of the reason is that the test reads like a state machine, fulfilling its documentation purpose. Ideally, I like 3-liner unit tests (one line for every stage), maximizing both readability and communication of intent (method extraction can help us make almost every unit test a 3-liner).\nWith the classicist approach I find that tests tend to grow large quite often, with complicated setups and assertions, which in extreme cases can defeat the whole documentation purpose (there is the name of the test to partially save this). This was definitely one of the notes I made while watching the clean coders comparative case study video series. Uncle Bob\u0026rsquo;s tests were lengthy.\n# Complex refactorings Since we are trying to flesh out the whole system starting from its core logic, it is quite probable to find ourselves in a situation where a class, deep inside the core of the application, has too many responsibilities or its design is cumbersome. Such cases, sometimes require drastic refactoring moves.\nComplex refactorings are never pleasant and the more complex they are, the more the likelihood of breaking the tests increases. Usually, I find it much more preferable to apply small refactoring tweaks than tearing the whole system apart, while trying to keep my tests green.\n# Treating the API as a second-class citizen Starting from the core logic of the application poses an extra problem. Thinking of the API is usually deferred until the implementation reaches it. One may argue that this is not a drawback, but we should always keep in mind when building a system that we do so only because someone else needs to use it. If we are writing a web service for instance, some client will consume this API, otherwise we wouldn\u0026rsquo;t be writing it in the first place.\nTherefore, I regard this as a considerable problem. We are running the risk of over-engineering our solution, implementing logic that will not be used. Don\u0026rsquo;t get me wrong here. Creating abstractions and achieving loose coupling between our HTTP layer and our domain is very much desired. I just find it really useful to begin my thinking from the API.\nI am really sitting on the fence regarding Uncle Bob\u0026rsquo;s abstraction decisions on the clean coders comparative case study video series, leaning a little bit towards considering them premature and therefore potentially harmful.\n# Outside-In # Strengths # TDD as a design tool One of the principal differences between the two approaches is in which state most of the design decisions are made. While in the classicist approach this is happening in the refactor state, in Outside-In the answer is the red state. When writing a failing unit test, we have to think ahead of ourselves and design. We have to decide what are the collaborators of the class under test going to be and how is this class going to communicate with them (public API) to fulfill this business requirement (test). These are core design decisions and are made before the implementation. Of course, design can be refined in the refactor step, but usually, in a much more light way.\nDespite some objections on this (more on this later on), I love the way TDD is really used as a design tool. During the JHUG talk/demo we discussed on how TDD does not magically create good design by itself. TDD gives us the time and place to design and this is done brilliantly in the Outside-In style.\n# Acceptance tests drive the architecture Earlier, I made the point how using the classicist approach can result in treating the API as a second-level citizen. I feel quite the opposite when using the Outside-In approach. Not only we start off with the HTTP layer, but the needs of this layer drive the rest of the implementation and architecture all the way to the classes deep inside in the domain. The whole system is built in a way that serves the clients\u0026rsquo; needs and therefore its purpose. Of course, we are free (and in fact encouraged) to create the right abstractions and seal our implementation, without compromising our attention to the API.\n# Adopting the client\u0026rsquo;s point of view While running our inner TDD cycles we are very diligent in mocking all the dependencies of the class under test and put a lot of thought in the stubs that we will use. As mentioned earlier, this is in fact design. What I particularly like about this design method is that we always focus on the way the clients of these mocked classes will interact with them. We are designing their public API, allowing ourselves to hide the implementation details behind this public API when the time comes to implement this class.\nWhat is so brilliant about this though process is that we always approach a new class from the point of view of its clients. We first think what kind of behavior we would like this class to provide in order to fulfill which business requirements (tests).\n# Test readability As opposed to the classicist approach, I love the way the tests read in Outside-In TDD. Arrange, act and assert are evidently separated, tests are relatively short and the intent is clearly expressed in a state-machine manner. Also, taking the \u0026ldquo;should\u0026rdquo; naming convention (which I absolutely love) into consideration, the executable documentation produced is all that one could ask for.\n# Method and discipline I left for last what I perceive as a vague, less objective advantage. When writing code using the Outside-In TDD approach, I always feel that there is method and discipline in my work. I feel that I am working very methodically. It is almost as if I am following an algorithm, approaching the problems in layers, breaking it down in small pieces and knowing exactly what needs to be done next and where am I in the whole process at any given moment. The acceptance tests acts like a north star that will not let you get lost while running the inner TDD cycles. This is mainly due to the fact that the way they fail will lead me to the point I have to pick up the implementation from when finished implementing a class.\nI understand that this is utterly subjective, but I do not feel the same way when using the classicist approach. Throughout the clean coders comparative case study video series I always knew where Sandro was and what was missing for an API to be finished, but I always had to think harder when Uncle Bob was driving the implementation.\n# Weaknesses # Refactoring limitations Throughout my journey to understand and adopt the Outside-In TDD style, I always struggled with the refactoring limitations that are posed by following this technique. In a nutshell, the mocking and stubbing that are heavily used result in tight coupling between the production and test code, with severe implications to refactoring capabilities.\nThis caused me great unease until I truly understood the deviation in the philosophy between the two approaches. In the classicist approach emphasis is first put on making it work and then on the structure of the code. Therefore, the room for refactoring in the refactor step is created because it is needed, given that this is where we largely shape the structure of the code. On the other hand, with the Outside-In approach, we focus on structure from the beginning, leaving less room for modifications in the refactor step since we anticipate less major modifications.\nIt does take some time to truly understand this differentiation in the way of thinking, but as soon as one does get it, it\u0026rsquo;s all very clear. In my perception, a profoundly uneasy state to be in is thinking in classicist terms (I will structure the code in the refactor step) when trying to apply Outside-In TDD.\n# Not suitable for algorithmic code As this approach focuses on dependencies and collaboration between classes, is follows logically that it is not an ideal candidate for implementing an algorithmic piece of code. Usually, there are no collaborators in such a case and therefore this technique will be of limited use. Therefore, this constitutes a perfect example to demonstrate cases in which we should switch to a different TDD style, such as the classicist one.\n# Conclusion TDD is a very handy tool to have in our arsenal and if we intend to be true software craftspeople, this arsenal better be mighty and better include both TDD styles. We ought to study and apply both of them and draw our own conclusions as to which one we favor in which situation and why.\nIn my opinion, judging based on the problem in hand is crucial and ideally we should learn to switch between the two. Don\u0026rsquo;t forget that in software engineering almost everything is a trade-off and working these trade-offs is what makes us better professional software engineers. There is no silver bullet for most problems and - despite personal preferences - TDD styles is not an exception.\n","date":"2019-03-25T00:00:00Z","image":"//localhost:1313/img/posts/tdd_flavours.jpg","permalink":"//localhost:1313/comparing-tdd-flavours/","title":"Comparing TDD flavours"},{"content":"How many times have you experienced software engineering teams that, regardless of the reasons, opted for quick solutions, resulting in poor code quality and created problems that accumulated over time? Where did this lead?\nEventually, the product resembles an iceberg. The stakeholders can only see the end result, the behavior of the system, the part of the iceberg that lies above the surface, unaware of what lies underneath it. However, the software engineers have the full picture. They know every aspect of the system and they understand the need to take some extra time to tide things up a bit more than usually once in a while.\nOn the other hand, the stakeholders, happy with the current image above the surface, most likely will never request to devote effort (time and money) to get (what they perceive as) a perfectly working product to a better shape, especially in the short loops of agile software development, in which they expect tangible business value every few weeks.\nIt seems like a dead end, but a truly professional team of software engineers should never allow themselves to result in such a situation. It\u0026rsquo;s their responsibility to be proactive about it. Let\u0026rsquo;s take things slow though and discuss a little bit about technical debt.\n# What is it The term technical debt refers to all the things in a code base that could (and should) be improved, but do not directly affect the behavior of the system. It\u0026rsquo;s the things that the software engineers know should be done in a different, better way, but either chose to defer for the future or realized later on.\nTechnical debt is code written today that requires more effort in the future\nThis resembles a lot a bank loan, in which an individual gets money today that require more money (initial amount plus interest) in the future to pay off, essentially creating debt.\nThe term technical debt is a metaphor, referring to quick win software solutions that will slow development down in the future in order to pay the debt off. Also, since typically future amendments require more time than it would be originally required to provide a proper solution, the debt is accumulated and paid with interest. Not paying the debt usually results in loosing the product, as the code base eventually becomes either unmaintainable or too expensive to maintain.\n# Where does it come from There ways in which technical debt can be created are numerous and very diverse. Some are easier to spot and even prevent, some are quite tricky and some are inevitable.\n# Unprofessional technical debt An easy to spot (and, most importantly, prevent) way of creating technical debt is simply not taking the time to do our job in the right way. Every time we opt for a hack, a quick-and-dirty solution, a workaround, every time we skip some unit tests or do not refactor the code, we create debt. Every time we are sloppy with our work because someone says that \u0026ldquo;this is urgent\u0026rdquo; or \u0026ldquo;needs to be done by today\u0026rdquo; and we succumb to this pressure, we create future troubles for our team and our organization.\nEvery time we cut corners, we create technical debt\nI am trying to put as much emphasis as I can to it and be harsh. Of course, coming up with a way to improve code or identify weaknesses is not only natural, but welcomed, especially as we become more mature. However, wittingly applying discounts - therefore creating this type of technical debt - is, in my opinion, absolutely unprofessional and irresponsible. Deliberately undermining our code quality to reduce time to market is an approach that will come back to bite us in the future. Period.\n# Outdated design technical debt Sometimes we start off with simple and robust design and architecture for the initial requirements of the system, but as time goes by and increments are added, we fail to adjust the design and architecture in a proportional way. This phenomenon is more likely to occur when new developers join the team and do not fully understand the original design.\nWhile this can be prevented too (by taking the time to adjust the architecture as we develop the system) it is not unlikely at all that (even when applying frequent incremental refactorings) there will be a point in time when more drastic changes are needed.\n# Software grew old technical debt Technology races forward in an astonishing pace these days and therefore we may find ourselves with a dependency that will become deprecated in the upcoming release (a database driver for instance). There is not much we can do about it and no one is to blame really. We should just take the time to keep our dependencies up to date. Of course, doing so proactively is much preferable to waiting for a deprecation announcement.\n# There will always be technical debt Of course, trying to always be technical debt free is simply delusional. Databases deprecate their old driver versions, systems grow enough to require that architecture should be revised and no matter how exceptionally we write a piece of code, as we grow more experienced and knowledgeable, we will always identify weakness and better ways to write it.\nIf we look back to a piece of code we wrote a year ago and find nothing that we would do in a different, better way today, perhaps we have remained stagnant for the past year.\nSo, technical debt will present itself no matter how professional and diligent we are.\n# And it\u0026rsquo;s OK This is a fact and we have to accept it. After all, we should always bear in mind that the iterative nature of shipping software is built on the foundation of feedback. We solve the problem, we deliver the solution, get feedback on it and then try to improve it. Trying to ship a perfect product will result in a tail chase.\nTechnical debt, comes hand in hand with agile products and innovation. Sometimes we have to prototype solutions. Most of the times we have to get a feature out quickly, just to get feedback and learn what the users really want (after all they usually don\u0026rsquo;t know what they want either, until they have a prototype to play with). This will create technical debt and we have to find our peace with it and embrace it.\nOf course, this is fundamentally different from ignoring it and just letting the code rot. On the contrary, it is something that should be dealt with, because it costs. And it costs a lot.\n# How costly is it A team or a product can be severely hurt by technical debt in multiple ways. Unfortunately, these problems tend to steadily grow under the radar and only become visible when it\u0026rsquo;s too late. Let\u0026rsquo;s discuss the ones I believe are the worst ones.\n# Development slows down What happens to a system when the code slowly rots? As Uncle Bob explains, it is becoming difficult to change. A single modification ignites a chain reaction that causes a cascade of modifications in dependent modules. The system is resisting to change. It is becoming rigid.\nThe more rigid a system becomes, the more development slows down. Gradually features require more and more effort to be implemented. The stakeholders have to wait more to get value and features become more expensive.\n# Reduced quality To make matters worse, developing features in a rigid system is far more error prone. Introducing defects is more likely in a highly coupled, complicated, rotten design than in a clean, frequently refactored one. This is observed as reduced quality, which although cannot be measured, can be felt by the stakeholders. In extreme cases, this can even result in performance issues.\n# Demoralization I saved the most sneaky and costly one for last. Chances are that a well taken care of piece of code will remain so and future software engineers that will touch it will go to great lengths to keep its quality high. On the other hand, sloppiness and low quality propagate tremendously fast within a code base. A badly written, poor quality, piece of code will most likely tempt the next software engineer to work on it to opt for a hack, or a quick-and-dirty solution. Andy Hunt and Dave Thomas use a great metaphor of a broken window to describe exactly this phenomenon in their book, \u0026ldquo;The Pragmatic Programmer\u0026rdquo;.\nThe poorer the quality, the faster more and more technical debt will accumulate, demoralizing the team and rendering the code a nightmare for any software engineer. This is a typical situation, which, more often than not, results in the best people leaving the product (usually the company as well) and set off for new adventures. This is not only costly for the product, but for the organization as well.\n# How to deal with it Having said all these, how are we going to approach such a tricky situation? The stakeholders definitely will not ask us to take time to address technical debt.\nMapping it to actual value can be a solution, but it usually turns out to be quite difficult. For instance, updating the database driver can improve the performance of the application, but how can we transform this into a measurable, well defined Product Backlog Item (PBI) that presents business value? How faster is the application going to be and how beneficial is this to the business anyway? Even if this can be achieved, how about refactoring to improve the application\u0026rsquo;s design? There is no way we can present tangible business value out of it. But it does reflect to business value in a shocking way.\nThere are multiple approaches, but let me present you mine. I suggest to reserve a corner of your scrum board for technical debt. Have every team member that comes across technical debt, write a sticky note about it and stick it to this corner. Also, take some time to discuss about it with the rest of the team (perhaps in the upcoming daily scrum). During planning, take this debt corner into consideration. When asked to refine, estimate or plan a PBI that (even remotely) touches an area with technical debt, include this debt sticky note in the PBI.\nThis method will not only make the team address technical debt in a proactive manner, dealing with it in the first chance, therefore keeping the code in a relatively good shape. It will also facilitate in working with the stakeholders to educate them on the value of software quality.\nThe latter may sound minor in comparison to the former, but sometimes it is the greater good between the two. An educated group of stakeholders is more likely to support software engineers in doing their job the right way.\nFinally, this method ensures that problems will never pile up and cause troubles. If an area needs improvement, it will be improved on the next task that touches it. Therefore, a situation in which an issue is added on top of an already existing one, is ruled out by definition.\n# Conclusion The accumulation of technical debt is a very sneaky problem, present in almost every code base. Negligence will accelerate the process, but even the most diligent group of engineers will not avoid the problem. Therefore, we have to embrace its presence. However, it can prove immensely costly, not only drastically reducing code quality and productivity, but also driving the best engineers out out of the product. So, it should be addressed.\nMaking it a part of our agile loop ensures that time will be taken to deal with it, people will become educated on it and it will be dealt with proactively. Regardless of the approach, letting technical debt accumulate and eventually cause serious problems to the product is not only a pity and wasteful, but also utterly unprofessional.\n","date":"2019-01-27T00:00:00Z","image":"//localhost:1313/img/posts/technical_debt.jpg","permalink":"//localhost:1313/dealing-with-technical-debt-in-an-agile-environment/","title":"Dealing with technical debt in an agile environment"},{"content":"Taking a step back and looking at something that you\u0026rsquo;ve been doing for years with a fresh perspective can lead to profound insights. I had an insight exactly like this a few months ago, when I decided to look at getters and setters from a different point of view.\nDuring my first steps as a software engineer, I learned about Plain Old Objects (POJOs for Java software engineers, like myself) and ever since it made sense in my head, I always took getters and setters for granted. It was something I had to do. Later on, I learned (although now I know that I did not fully understand at the time) about the notion of encapsulation and how these getters and setters are a key step to achieving it. It then made even more sense to always code (or rather generate) them in every single POJO in my code.\nSo I did consistently, until I read a blog post that got me thinking and revisiting the whole concept of encapsulation in a fresh, unbiased way. Now, that I believe the dust has settled, I will try to communicate my thoughts on the matter in this post.\n# Object-oriented design It all starts with true object-oriented design. If one goes online looking for a definition and a brief description of Object-Oriented Programming (OOP), one will come across (among some wise stuff) all kinds of nonsense. They usually start with something like \u0026ldquo;OOP is about modeling the real world\u0026hellip;\u0026rdquo;. Well, it\u0026rsquo;s not.\nOOP is a design philosophy according to which, a software system should consist of a set of self sustainable objects and messages that can be passed between these objects. Now, notice that the two key words here are self sustainable and messages. In other words, our objects should be:\nempowered to accomplish what lies within their responsibility (which had better be a single one) and their outside world (other objects) should have a way of telling them what they need them to do This is really straightforward. Let\u0026rsquo;s assume that we have an AirCondition object. What we would like is to be able to tell it to adjust the room temperature to (say) 25 degrees Celsius and for it to be able to do so. Notice that we are not interested in how is it going to achieve this. All we want is to command it and have the job done. Essentially, we are sending a message. We are delegating the task. Now, this brings us to the point that we can understand both what encapsulation is and why we need it.\n# Encapsulation The gist behind the notion of encapsulation is that the objects should not reveal their internals (implementation details) to the outside world (other objects). They should be like black boxes, providing an interface for the world, allowing it to tell them what needs to be done. All the details of how they achieve the tasks that are told to achieve it\u0026rsquo;s their business and no one else\u0026rsquo;s.\nIn a technical level, an object exposes a set of public methods (API) and probably uses variables and data structures to manage it\u0026rsquo;s state in order to perform the tasks that it\u0026rsquo;s told to perform.\nEncapsulation mandates that the state of the object should be kept private, unknown to the external world, at any given time.\n# The problem with getters and setters This is exactly where getters and setters enter the picture. Conventional wisdom has it that since the object\u0026rsquo;s properties are to remain \u0026ldquo;hidden\u0026rdquo;, they should be wrapped by a getter and setter each, enabling the external world to \u0026ldquo;access\u0026rdquo; them, without learning about the object\u0026rsquo;s state. Now, pause for a minute and read this last sentence once again before proceeding. Does it make any sense at all? At the end of the day, what difference does it make if we are to use the properties either directly or via their wrapper getter and setter? Essentially we are messing with the object\u0026rsquo;s state in either case - which is quite overtly exposed to the public via these methods.\n# An example In order to better illustrate the nature of this problem, let\u0026rsquo;s consider for a moment the AirCondition class from above. Suppose our intention was to adjust the room temperature to 25 degrees Celsius. One could achieve this via the following piece of code:\nif (airCondition.getTemperature() \u0026gt; 25) { while (airCondition.getTemperature() \u0026gt; 25) { airCondition.decrementTemperature(); } } else if (airCondition.getTemperature() \u0026lt; 25) { while (airCondition.getTemperature() \u0026lt; 25) { airCondition.incrementTemperature(); } } However, all we do is constantly manipulating the object\u0026rsquo;s state, essentially implementing the logic that it should possess. We are micromanaging the object. Instead, we should trust it on knowing how to do its job. We keep on asking about it\u0026rsquo;s state and then modify it instead of telling it the end result that we wish. Conforming to OOP, all we need to do is to send it a message, like the following\nairCondition.adjustTemperatureTo(25) and it should get the job done, because it knows how to actually do it. We shouldn\u0026rsquo;t even know if there is or there is not a property holding the current temperature, let alone query for it directly. This is part of the means the AirCondition class could use to achieve its purposes, it\u0026rsquo;s subject to change at any given moment and its strictly its own business.\n# Tight coupling We all know (at least in principle) that our classes should be highly cohesive and loosely coupled. The theory is great, but let\u0026rsquo;s consider how these guidelines (about coupling in particular) apply to this specific example.\nLet\u0026rsquo;s assume that we wish to refactor the AirCondition class. Perhaps we would like to rename the temperature variable to currentTemperature. Performing this elementary refactoring move, would create a chain reaction, causing all the classes that depend upon it (its collaborators) to fail to compile and impose the need to refactor them too. Perhaps, some collaborators of these collaborators should be refactored as well and so forth.\nThis scenario illustrates perfectly the side effects of a design with tightly coupled classes. However, on the second, imperative approach, the collaborators of the refactored, AirCondition class would remain unaffected, agnostic to the modification. We can therefore conclude that the imperative approach has led to a more loosely coupled design.\n# Tell, don\u0026rsquo;t ask Some of you might have already noticed that these ideas start to sound a lot like the Tell, don\u0026rsquo;t ask principle (also known as Law of Demeter). (In case you\u0026rsquo;re not familiar with this principle, feel free to look it up online as I will not delve into its details in this post). The essence behind the principle, which is in total accordance with the previously expressed ideas is that objects are not to be treated as data structures. Splitting the data and the operations on these data in different objects is not wise.\nData and functionality that depends on these data belong in the same object\n# A story and a lesson learned Once, while working for a company heavily based on microservices, I had to implement a small feature in a microservice I wasn\u0026rsquo;t normally contributing to. While studying the code I quickly realized that it was a common practice to access class properties directly. I actually ended up walking into a tech leads meeting trying to explain both what encapsulation is and why it would be beneficial to use it, by wrapping properties with getters and setters.\nEventually, I failed to pass the message (at least adequately enough to initiate a change), which made me sad, but what made me even sadder was the realization, later in my life, that even if I had convinced this group of people to start using getters and setters instead of directly accessing the properties, essentially not a thing would have been changed in terms of the quality of the code and the product.\nAt the end of the day, what difference would it make to use airCondition.getTemperature() instead of airCondition.temperature? Perhaps that is the reason why the designers of Kotlin decided to provide getters and setters by default, without even going into the trouble to code (generate) them or even call(!) them (in Kotlin airCondition.temperature actually calls airCondition.getTemperature() under the hood).\n# Amending the situation Assuming that the problem is clear, a reasonable question to ask would be what to do to amend it. A very helpful first step would be to stop writing getters and setters this very moment. This would surface cases that collaborators need access to another classe\u0026rsquo;s properties.\nWhen you face such a situation, take a moment and reflect. Do you really need to expose this property? Is there a better way to solve the problem? Perhaps, instead of exposing the property, a new method can be introduced in the object to receive the message that an operation needs to be performed. Exactly the operation that the collaborator who wanted access on the property was about to implement. Whose responsibility is this operation?\nSometimes getters and setters will be needed, but I reckon that most of the times, different, better object-oriented solution will present themselves. This will gradually improve the design of the system you are working on.\n# Conclusion Object-oriented design is all about passing messages between self sustainable objects and ecapsulation is a tool that can be immensely helpful on this task by resulting in loose coupling. On the other hand, letting our classes see deeply into the internal implementation of their collaborators, essentially results in tight coupling.\nWrapping class properties with getters and setters helps look deep inside the internals of other class. It provides a false sense of encapsulation, but even worse, it pushes us towards treating classes as mere data structures and implementing the logic that these data serve in collaborators, defeating the very purpose of true object-oriented design.\nExperiment by stop writing getters and setters instead and observe the side effects. I strongly believe that it will lead to a better design.\n","date":"2018-12-09T00:00:00Z","image":"//localhost:1313/img/posts/encapsulation.jpg","permalink":"//localhost:1313/how-getters-and-setters-harm-encapsulation/","title":"How getters and setters harm encapsulation"},{"content":"How many times have you found yourself engaged in a retrospective, wondering why do you lose all this time? How many times have you committed to action items that no one ever dealt with in any way? How many times have you caught your team or yourself discussing the same issues again and again thinking that this will not be the last time?\nRetrospectives are very hard-to-drive meetings. The hurdles to overcome are countless. Team members that will not open up, team members that dominate the conversation, inability to identify root causes, lack of commitment to action items, frustration and politics, just to name a few. Sometimes the Jocker (Scrum Master) has to display a great arsenal to keep all of these under control and - above all - meaningful.\nMy intention in this blog post is to share part of the knowledge, experience and lessons learned by driving retrospectives. Despite mainly referring to people facilitating these sessions (Scrum Masters), I believe that all members of a scrum team could benefit by it. Throughout this post, I will be referring to sprint retrospectives, but these principles, more or less apply to all kinds of retrospectives (release retrospectives, departmental retrospectives etc).\n# The Goal Before we even begin talking about how to carry out successful retrospectives, let\u0026rsquo;s think for a moment why we have them in the first place. This meeting is a key part of the ever ending inspect and adapt loop. It\u0026rsquo;s the team\u0026rsquo;s official slot reserved for thinking what we did during the last sprint and how could we improve it.\nBear in mind that this is the last resort for improvement. The proper moment is any moment. As soon as we know that something could be improved, we should try to improve it right away. When you come across any pain point, don\u0026rsquo;t forget that the retrospective is now! However, this runs the great risk of never prioritizing and never doing it and therefore, the sprint retrospective is there to force us to work on these issues.\nThe goal of a retrospective is to produce action items\n# Structure One of the great pitfalls to be avoided is not preparing a retrospective before facilitating it. Structure and preparation are key to the success of the retrospective and there is a reason for it. Team members often get emotional or carried away when engaged in retrospective conversations (they are supposed to after all) and it can be very easy to lose sight of the goal and spend the session in a meaningless way.\nAlways make sure that you know exactly how the session unfolds relative to the schedule. Is it going too slow? Are we spending too much time on this topic? How far behind are we? Can we cover it and in which way? Always make sure that there is enough time to reach to action items.\nIn an ideal situation, a mature team should be able to walk into the retrospective and just share their thoughts, drive the discussion to conclusions and action items, commit on working on them and move on with the following sprint. However, since this is barely realistic, I always use exercises to put the team in the right context and help them focus on identifying strengths and weaknesses. An excellent source of exercises is retromat. In the vast majority of the retrospectives I have facilitated, I have broken the structure down to the following five sections.\n# Set the stage Usually, 5-10 minutes for a 90-minute retrospective, depending on the team size\nTake the time to communicate the purpose of the session and the schedule. It may sound redundant, but it will help the team members orient themselves during the retrospective and focus on the task in hand for the following period of time.\nUsually, I ask for a very brief check-in phrase or input (e.g. describe the previous sprint in 3 words). Simplistic as it may sound, keep in mind that there may be people in the room that are hard to open up. As Scrum Masters, we should always make sure that every team member feels comfortable to speak and is engaged in the team exercise. This is what I focus on during this short phase. Get everyone onboard for what\u0026rsquo;s about to follow.\n# Gather data Usually, 20-25 minutes for a 90-minute retrospective, depending on the team size\nThis is the time to identify what went wrong (or could just be improved) and what did the team do well (this is also very important).\nUse an exercise that focuses on plain facts. Ask for both negative and positive facts. As it is important to amend any problematic areas, it is equally important to preserve the good habits. Preferably, before discussing, allow the team some time to silently think and jot down a few things on sticky notes, in order to avoid affecting each other\u0026rsquo;s thought in this part. If necessary, you may feed the team by mentioning one or two defective ares that you recognized during the sprint, prior to the exercise, to get them going and accelerate results, but be very careful not to guide them.\nThis is an extremely important step, as it will feed the rest of the retrospective with data. If the team fails to come up with the right issues here, it is almost inevitable that the real issues will remain untouched, no matter how great the effort in the rest of the session.\n# Generate insights Usually, 20-25 minutes for a 90-minute retrospective, depending on the team size\nHaving identified the major pain points in the previous step, it\u0026rsquo;s time to address them. The point of this step is to come up with potential solutions to these pain points, but do not neglect to preserve the good habits as well.\nPick an exercise to help the team interpret the data gathered from the previous step and come up with action items to both address the problems and preserve the good habits. Usually, I avoid a lot of conversation and interaction up to this point to keep the process of gathering the data impartial, but this is the point to allow collaboration to kick in (e.g. working in pairs or have a lot of conversation). Make sure the team members are interacting in a productive way. If the items from the previous step are too many, ask the team to prioritize them and work the list top to bottom until the allocated time (or the list) runs out. Ideally, by the end of this step a list with ideas (solutions to problems, things to start/stop/continue doing etc) is composed and lies visible to the team (e.g. sticky notes on the wall, whiteboard etc).\nAlways keep in mind that this is the very heart of the retrospective. Tension may be caused, strong arguments may take place. This is healthy and desired, but always make sure that the situation is under control and is actually going somewhere. As a Scrum Master, make sure that personal attacks are avoided, only productive arguments are hold and the team mainly deals with items that is actually empowered to change.\n# Decide what to do Usually, 20-25 minutes for a 90-minute retrospective, depending on the team size\nPresumably, most of the hard work is over. A list of action items is in the team\u0026rsquo;s hands. What is left is to decide on a reasonable amount of action items to work on the upcoming sprint.\nIn this step, I always like using exercises that foster collaboration (and conversation) and create clear, unambiguous results. For instance, an impediments cup facilitates prioritizing action items, creating a clear result and engage in discussion while doing so.\nBasically, this is a matter of prioritization. All action items are useful, but the team has to commit to a reasonable number of them. This depends on a lot of factors (size of the team, difficulty of the action item, sprint length etc). Make sure that the decisions are taken collaboratively (but not chase after consent, as it can kill the retrospective) and the reasons for them are clear to the team. Additionally, be very careful not to use a process that creates winners and losers, as this can hurt morale.\n# Close the retrospective Usually, 5-10 minutes for a 90-minute retrospective, depending on the team size\nThis step can be used to both get feedback on the retrospective and close the session in a light tone. It\u0026rsquo;s very likely that as problems surfaced, people opened up, things got tense and there were disagreements. This was very desired indeed, but as the session draws to a close, the point is to leave all these behind, keep all the hard work and close in a good mood in order to begin the next sprint.\nAny very brief exercise will do for this part. Just make sure that as you achieve the above-mentioned goal, you\u0026rsquo;re not tiring an already exhausted team. Preferably, choose a fun and invigorating exercise.\n# SMART action items Perhaps the biggest pitfall for a retrospective is to come up with action items that are not SMART. There is a huge difference between action items and wishful thinking. For instance, consider the following two outcomes of a team\u0026rsquo;s retrospective:\nImprove collective ownership of the code.\nNo self merges. All code will be reviewed by at least one more engineer before being merged. Bob will monitor it and in the next retrospective will let us know if we succeeded or not.\nDo you see the difference? For an action item to be meaningful, it has to be:\nSpecific Measurable Agreed upon Realistic Trackable # Dealing with silent team members Getting people to open up can be one of the trickiest tasks for a Scrum Master, but it constitutes a key ingredient for a fruitful retrospective. People may be quiet due to their personality or because they choose to remain silent for their own purposes. Both cases are difficult to handle, but each requires a different approach.\nWhen dealing with team members that are shy or not very outgoing, remember to work hard with them while setting the stage. Before leaving this step, make sure that they have shared something with the group. This will make them feel more engaged and will increase the probability that they will share more during the retrospective. If necessary, during the retrospective, explicitly ask them to comment on a topic, especially if you know that they have an opinion on the matter, but they are obviously reluctant to share it.\nWhen people remain silent driven by politics, the spectrum of options is considerably narrowed down. What I feel is useful is to state once again that the purpose of this session is to improve as a team and in order to do so, sincere input and respect by everyone is a prerequisite. However, an individual who chooses to play his own game most likely will not change his path by such a speech. I would also suggest to drive the rest of the team to open her up.\n# Dealing with team members that dominate the conversation On the other hand, having a team member that simply dominates all conversation is a definite disaster for the outcome of the retrospective. A team member may do so either wittingly or unwittingly. In any case, find a suitable point in her speech and interrupt her. Make sure you are very polite, but firmly explain that this session cannot work like this and the team will lose sight of the goal in this manner. Strive to achieve that discussion is as evenly as possible distributed throughout the group and all have a fair chance of expressing themselves.\nThis is not an easy situation to be in. No matter how polite you are, chances are that the person you interrupt will feel offended (even if she doesn\u0026rsquo;t show it), but do not yield to this thought. In the past, I have driven retrospectives that suffered for this exact reason, because I never summoned up the courage to interrupt this person. Hopefully, I\u0026rsquo;ve learned from my mistakes.\n# Keep the conversation productive The moment the conversation is derailed, the retrospective is immediately jeopardized. Having team members aimlessly discussing instead of trying to reach to the root cause of problems and solve them can be a disaster. Personal attacks and conflicts can cause this. Make sure that you are very strict on this and put the team back on track as soon as you realize it. Additionally, discussing on items that are out of the team\u0026rsquo;s reach can also kill the retrospective. Make sure that you spend no time on such topics.\nA team that tends to frequently focus on items outside of its power is in danger of essentially wasting retrospective after retrospective dealing with issues that they will never be able to solve. Also, as they are convinced that an external factor is slowing them down, they run the risk of lowering their own morale and start feeling underprivileged. Kill this as soon as you notice it. No matter how disastrous these external factors are, this is the time to focus on improving the internal team functioning. An excellent exercise to help you with this is Circles \u0026amp; Soup.\n# Avoid creating a routine As soon as retrospective starts feeling like a routine, do something to disrupt this. During this session, we want team members to be creative and think outside of the box. A routine is the worst enemy of this.\nAlways strive to keep the team energized and keep the blood flowing. Use exercises that require standing up and walking in the room. Keep it playful. If possible, change the room or the time the retrospective takes place. Whatever you do, do not create a routine.\n# Conclusion Driving a retrospective is a very tricky business. However, retrospectives are key to the healthy functioning of an Agile team. Make sure to prepare beforehand and constantly keep in mind that the team should be after SMART action items. Don\u0026rsquo;t let it be derailed and the hard work is definitely going to pay off. Finally, never forget. The retrospective is now.\nP.S. Feel free to share your thoughts or comment on mine. As always, I would very much love a nice, productive conversation on the topic.\n","date":"2018-11-10T00:00:00Z","image":"//localhost:1313/img/posts/fruitful_retros.jpg","permalink":"//localhost:1313/driving-fruitful-retrospectives/","title":"Driving fruitful retrospectives"},{"content":"Scrum has gone wrong in a number of ways. This is a fact. Agile, an initiative born by software engineers, has turn into a new, cool product management way. A considerable number of companies advertise that they use scrum when all they do is run a standing, 15-minute meeting in the morning and use sticky notes, being totally oblivious the true mindset of the framework as well as the immense benefits that it can provide.\nAmong a lot of factors that have resulted to this, arguably the king of the problems is how people misunderstand the concept of the velocity of a scrum team. Scrum Masters and Product Owners treat it as a productivity reporting tool, trying to make the development team commit (we will discuss this \u0026ldquo;commitment\u0026rdquo; issue in another post) to as high a number as possible, while the development team, feeling that they are judged by this number, struggle to increase it sprint by sprint. However, this is a fundamentally flawed view.\nVelocity is not a productivity reporting tool!\nI wish I could stress this even more. Velocity is not a productivity reporting tool!.\nSince I - once again - started with what velocity is not, let\u0026rsquo;s proceed in a more conventional way and talk about what velocity actually is.\n# Inspect and adapt Let\u0026rsquo;s try to go back to the basics and essence of Scrum for a bit. In a nutshell, every couple of weeks (in reality this number ranges between 1 and 4 weeks, but for simplicity\u0026rsquo;s sake I will use 2 weeks for a sprint\u0026rsquo;s length throughout this post) the scrum team gathers with the stakeholders, reviewing their latest increment, inspecting the state of the product and refining the priorities. After this comes the retro and after the retro, the new sprint begins with a sprint planning session: the most important meeting in scrum.\nNow the scrum team should take into consideration the outcome of the sprint review and retrospective in order to commit to a new sprint. A new sprint, which should accommodate the prioritized requirements of the product, as defined by the stakeholders, whose voice in this meeting is the Product Owner. Let\u0026rsquo;s think of this for a moment. How is the scrum team supposed to commit to a couple of week\u0026rsquo;s worth of work without having an estimate on the amount of work they can deliver in this time?\n# Sprint planning In order to execute a sprint planning session meaningfully, there have to be two inputs: a refined Product Backlog and the team\u0026rsquo;s calculated velocity for the upcoming sprint. These will produce a single output: a sprint backlog. The Scrum Master should see to this.\nNow it is becoming visible that the team\u0026rsquo;s velocity is key to deciding on how many and which Product Backlog Items should the scrum team work on the upcoming sprint. This is an indication, which the team should consult when asking questions like \u0026ldquo;is this amount of work a reasonable chunk for the upcoming sprint? Is it too much? Should we work on more items\u0026rdquo;.\nIf it is reasonable for one to assume that the team is able to successfully work on more items than they actually put in the sprint backlog, then the team is undercommitting and therefore failing to honor their role as professional software engineers. If the team is clearly committing on a sprint that will most likely fail to deliver, it is overcommitting, failing once again to honor their role as professional software engineers, as they create expectations for the stakeholders that they will not be met.\nThis is exactly why velocity is critical to the success of a sprint planning session and therefore to the success of the sprint. Velocity helps creating a sustainable pace. This pace will neither burn the team out or leave it idle for too much. Additionally, it provides confidence to the development team to estimate their upcoming work in reasonable chunks. Chunks that they can actually deliver, therefore causing the trust of the stakeholders in the development team to increase.\n# Calculating the team\u0026rsquo;s velocity Now, having said all these, I hope that it is clear that monitoring the team\u0026rsquo;s velocity is very very important, but who actually is responsible for this and how can one do a good job on it? After all, no one can predict the future and the work that a group of people will produce in two weeks time seems quite hard to get right.\n# Who # The Scrum Master\u0026rsquo;s role The Scrum Master is sometimes called the joker and part of the reason is that she has a lot of balls in the air at any given moment. One of these is that she is responsible for monitoring the team\u0026rsquo;s velocity and coming up with reasonable calculations for upcoming sprints as input in the sprint planning sessions.\n# Who else needs to know I once was working in a company that used to start the sprint reviews with the following phrase: \u0026ldquo;Our estimated velocity for the past sprint was \u0026hellip; and our actual velocity was \u0026hellip;\u0026rdquo;. I completely disagree with this (I had stated it a number of times)! Velocity is a piece of information that, in my opinion, concerns solely the scrum team members (perhaps excluding very few cases).\nThe stakeholders definitely need not know the velocity of the team. They only need to know that the team is maturing and can be trusted in their estimates. Otherwise, this would only enforce the view that the development team\u0026rsquo;s productivity is being judged by their velocity (at least in their eyes).\nThe Product Owner should learn the calculated number by the scrum master for the sprint planning purposes, but should not be concerned thereafter.\nThe development team should learn the calculated number by the scrum master for the sprint planning purposes, but should not be concerned thereafter either.\n# How Estimating the velocity of a scrum team for the upcoming sprint is not a straightforward task. Estimation by itself is not an easy task anyway. Needless to say, there is no silver bullet for it. But the good news is that there doesn\u0026rsquo;t have to be one. We\u0026rsquo;re not after a precise, infallible estimation. We\u0026rsquo;re after creating rhythm, building confidence and trust.\nA number of techniques are being daily applied by different Scrum Masters in different teams. None is right. None is wrong. Let me try to describe a technique that I have used for quite a long time and I find it useful.\n# One technique In the heart of the technique lie statistical calculations based on empirical data. A number of factors that affect the estimated velocity, are literally plugged into an formula that produces the magic number. The factors are listed and explained below:\nTeam members: The number of members of the development team. Do not confuse this with the number of members of the scrum team, which will be different if either the Scrum Master or the Product Owner do not contribute to writing code. Sprint duration: The days which will be available for the scrum team to complete its work in the sprint. Personally, I do not include the day of the scrum events, as no code is written during this day. No workdays: Days during which the team will not be working during the sprint (e.g. bank holidays, conferences that the whole team attends etc) Team holidays: Days during a single team member will not contribute to the team\u0026rsquo;s work (e.g. annual leave). For instance, if a member has submitted annual leave for a day and another member for two days, this number will be 3. Focus factor: A number indicating how reliable the team\u0026rsquo;s commitments tend to be. I explain this factor in depth further on. Actual work days is produced by the following formula:\n(Team members * Sprint duration) - (Team members * No workdays) - Team holidays\nFocus factor is a bit more complicated. Basically, the piece of information that we want to take into consideration is the degree in which the team estimations match the actual work done. The reason for using more than one past sprints is that as teams change, as they mature they go through different phases. These affect their focus factor. For instance, as a new team member is integrated with the team, one would expect the focus factor to have an slightly increasing trend. The focus factor for a single sprint is provided by the following formula:\nActual velocity points / committed velocity points\nFinally, the formula producing the estimated velocity for the upcoming sprint is the following:\n(Actual work days) * (average focus factor of the last x sprints)\nI usually use the average focus factor of the last 3 sprints (x = 3), but feel free to use any number of sprints that works for you\nI find it very convenient to use an excel spreadsheet for these calculations. I just plug the numbers in every sprint and I have both the calculations ready and reliable metrics and statistics when I need them. (I have a template for this spreadsheet. Do not hesitate to ask me for it. I will gladly share it.)\nNever forget that this number is a statistical calculation. Reality is much more complex. So, before committing to a sprint backlog, always make sure that the team believes that this is a reasonable chunk of work for the upcoming sprint. Ask them to forget about the number and actually do a gut feel. Don\u0026rsquo;t just blindly follow the output of any formula or technique.\nProbably a couple of very reasonable questions have already formed into your mind, like \u0026ldquo;What do we do on the first sprint, with no previous data existing yet?\u0026rdquo; or \u0026ldquo;What if a new member joins the team?\u0026rdquo;. Let\u0026rsquo;s discuss these both.\n# First sprint A very challenging period to estimate a team\u0026rsquo;s velocity is right after the team is formed. After all, there are no previous data whatsoever. There is no silver bullet for this problem either, but I would propose the following method: make sure that for the first few sprints the team bluntly overcommits. Not slightly overcommitting, but estimate a profoundly unreasonable amount of work. Explain to the team that this is happening for precise reasons and no one is expecting them to deliver this mountain of work. Protect them from destroying their morale! Now, over the first sprints (I believe roughly 3 will suffice), the current ability of the team will become clear. When confident, stop this and use a proper method for calculating the velocity, like the one described above.\n# New team member A usually confusing case is when a new software engineer joins the development team. Intuition suggests that the team\u0026rsquo;s velocity should increase. After all, there is one more engineer now, right? This is true, but in the long term. On the contrary, over the first few sprints, it is more likely that velocity will drop. Obviously, the new engineer, no matter how skillful, is not going to be productive right away. To make matters worse, the current engineers will have to both spend time on her orientation and keep on carrying out their regular work. This leaves them with less time to do the latter. Therefore, the most likely scenario is that velocity will drop slightly for the first few sprints and then gradually catch up and probably exceed the previous numbers (of course this also depends on how the new team will glue together, but this is another post).\n# Conclusion Perceiving velocity as a productivity reporting tool is flat-out wrong. Productivity is measured indeed, but not for reporting. Just for internal use within the team. Use it to create a sustainable pace, to help the team deliver on a steady basis, create trust and mature the team. The actual method for calculating the velocity for upcoming sprints does not matter. There are loads of techniques out there. Either pick one or create your own. Just make sure that you use it in the right way and it helps the team.\n","date":"2018-09-23T00:00:00Z","image":"//localhost:1313/img/posts/velocity.jpg","permalink":"//localhost:1313/working-the-velocity-of-a-scrum-team/","title":"Working the velocity of a scrum team"},{"content":"One of the most disturbing questions I often get refers to the percentage of the code that should be covered by unit tests. This is a perfectly fine question coming from a fairly inexperienced developer, but it troubles me greatly in virtually any other case. However, what urged me to write this post is that I gradually become aware of more and more organizations that actually impose rules on this metric. Rules like \u0026ldquo;the project must have 90% code coverage\u0026rdquo;.\nNow, there is a number of issues with this kind of approach. What if we get a 99% code coverage and we keep on getting bugs regularly? Does this 99% reflect code quality? Is it wise to impose rules on the developers, forcing them to reach a certain number on the metric? Can one write a suite of tests that cover all the code, but essentially test nothing? Is this meaningful? and more importantly, why are we testing in the first place?\nBefore we delve into the topic, let me clarify the following: practicing TDD as a discipline means that code coverage should approach 100% (but never quite reach it actually). However, since this post does not refer only to TDDers and even applying TDD won\u0026rsquo;t result in a 100% code coverage (one can easily understand this taking into consideration configuration files, Data Transfer Objects etc), I would like to take a more pragmatic view and discuss on the mentality behind all these.\n# Example Allow me to begin with an example that will help us understand the nature of the problem in hand. Let\u0026rsquo;s consider the following, very simplistic function that performs division between two integers (it\u0026rsquo;s hardly reasonable to assume that anyone would need such a function, but let\u0026rsquo;s consider it for the sake of the argument).\npublic int divide(int a, int b) { return a / b; } How many tests should we write for this function? Which tests should these be? It\u0026rsquo;s fairly obvious that a single test would result in a 100% code coverage for this one-liner. Is this sufficient? Now let\u0026rsquo;s take a step back and reflect for a moment.\nHow many states can this piece of code be in?\nA state would be a = 1 and b = 1. A second state would be a = 1 and b = 2 and so forth. Therefore, the combinations of all the possible values of variables a (the numerator) and b (the denominator) gives us the answer. Assuming that a and b are both java integers, each can take a bit over 4 billion values. Therefore, the states that this piece of code can be in are 4.000.000.000 squared!\nHopefully, by now, my point is illustrated. It\u0026rsquo;s very easy to reach 100% code coverage and yet, we have tested only 1 out of 4.000.000.000 squared states.\n# Meaningful testing Having understood the problem, what should one do? Opt for trying to test each and every state is clearly not only insanity, but very wasteful too. On the other hand, staying rest assured with the impressing 100% code coverage, created by the first test, is clearly not the right option either, since, clearly, a very problematic set of states remain untested: the ones when b (the denominator) is equal to 0.\nEnter on of the most important virtues of unit testing: meaningfulness. Coming back to the previously asked questions, I believe that testing a couple \u0026ldquo;regular\u0026rdquo; cases and one with the denominator equal to 0 (I guess, expecting an ArithmeticException to be thrown) makes sense and is probably what most software engineers would do.\nHowever, consider our choice of tests. Can anyone actually prove that these tests suffice to cover this piece of code? Is there a mathematical formula that can produce this set of tests as the right answer to the question of how many and which tests should we write? Absolutely no. Can it be the case that we were actually careless and have missed a bug after all? Absolutely yes. This is nothing more than a sensible result, a meaningful suite of tests for this piece of code.\nOf course, this example, being very simplistic, leaves almost no room for error. However, one can understand that in real world situations the margin for error is significantly increased and being meaningful in choosing the test cases takes a whole lot more importance. However, meaningful testing is not a quality some developers are born with and some other are destined to never possess. It\u0026rsquo;s mainly built through trial and error and derives from experience. So, perhaps, next time you face a bug, take a moment to think why it wasn\u0026rsquo;t covered with a unit test in the first place (by the way, also never forget to add that unit test, but this is another topic).\n# Avoid meaningless tests Quite often, the very constraint on a code coverage number can be very harmful. People tend to forget why are they testing and start writing tests just to satisfy the numbers. Junior developers get the wrong stimulae, which shape their careers in the wrong way.\nMeaningless tests, tests that test nothing become part of the regression suite, polluting the project in a unique way. They may fail frequently, causing the developers to ignore them, causing a total lack of trust in the test suite, or, even worse, they may be green all the time, even when a defect is introduced to the system. In either way, credibility in the test suite is lost, refactoring becomes harder and harder and eventually the project rots.\n# Follow the trend Coming back to the situations where organizations enforce specific code coverage numbers - I hope that by now the fundamental problems that lie with this approach have become apparent - what would a sensible policy be? We\u0026rsquo;re not actually suggesting that code coverage is totally useless, right? Of course not. On the contrary, it can be immensely valuable.\nHow should it be used then?\nThis constitutes ground for experimentation and I would very much like to hear anyone\u0026rsquo;s views on the matter. For now, let me describe an approach that I find useful. Start monitoring the code coverage and create a trend line metric for it. Make sure that, before merging a merge request, the line does not drop. If it does so, kindly ask the author to amend this, before merging the code. This can even constitute a condition in the team\u0026rsquo;s DoD. I believe that a lot of CI tools will provide plug-ins that help implement this policy (personally, I have used Jenkins and JaCoCo).\n# Untested code Instead of missing the point and start chasing after numbers just for the sake of it, use code coverage as what it really is: a tool. Make sure you go thoroughly over the report (tools like JaCoCo produce an extremely detailed report) on a regular basis. This can point out quite a few interesting things, such as untested parts of the code. Identify them and act on them. Perhaps a pattern will become visible. Find the problem and address it.\n# Quality testing Getting fixated on the code coverage number will harm both the developers and the project they\u0026rsquo;re working on in the long run. Instead of it, try to create a culture that focuses on quality testing. Make sure that the right tests are being written, the engineers start to gradually trust their test suite, enabling them to refactor the code as often as they find useful and bugs that slip into production become less and less. At all times, remember that:\nLow code coverage means that there are problems. High code coverage means nothing at all on its own.\n# Conclusion Code coverage is a great tool, but use it wisely. Stay clear from useless, arbitrary rules and constraints. Oppose yourself to them, no matter who imposed them, with grounds. Raise the coverage as high as possible, but as a result of responsible, meaningful, quality testing and think hard on any poorly tested (or even untested) areas. Focus on the ability to refactor using tests as a safety net and catching bugs as early as possible. As always, forget about the rules. Stick to the essence.\n","date":"2018-08-27T00:00:00Z","image":"//localhost:1313/img/posts/code_coverage.jpg","permalink":"//localhost:1313/how-much-code-coverage-should-i-have/","title":"How much code coverage should I have?"},{"content":"Among other things, scrum is very \u0026ldquo;trendy\u0026rdquo; lately. Virtually any company that I know of has either adopted it or attempted to do so or at least considered it. The software industry needs change rapidly, evolving the scrum master in one of the most sought after roles. However, the inability of the offer to meet the demand and the absence of required technical skills to become a scrum master has made the role appealing to a number of people outside the industry, giving birth to an ongoing debate. Should the scrum master have a technical background?\nThe scrum guide does not prescribe technical skills as a prerequisite for a scrum master. However, desired qualifications in vacancies range from concrete experience as a software developer to no technical requirements specified at all.\nBefore we endeavor to address the topic, let\u0026rsquo;s take a step back and think a little bit of Agile. Why do all these people and companies favor Agile over waterfall? After all, waterfall was used for so many successful projects. This can be a surprisingly hard to answer question for a lot of people.\nIn my opinion, the key benefit is the establishment of a short feedback loop.\nDaily stand-ups, open space offices and loads of sticky notes only serve to alter the process, being merely means to an end. The short feedback loop is an end in itself.\nAgile suggests that we leave behind the old days when the requirements were specified all upfront and the developers worked isolated for a few months only to deliver software needing change. A very short loop is established, allowing for a small chunk of software to be produced, inspected by the stakeholders, adapt to their feedback and repeat the cycle. Indefinitely. The illusion of the end state is eliminated.\nThis radical process modification requires profound changes in the heart of our work. Potentially, the most common pitfall is to change the process, but continue writing code in exactly the same way. A lot of companies, perhaps unwittingly, opt for only changing the process, starting walking down a road that is doomed to lead to failure. The scrum master enters here, forced to distance herself from solely the process and look at the bigger picture.\nGuarding the process is essential, but it means nothing without guarding the practices that lead to better software quality.\nOf course, quality cannot be measured, but there are disciplines that lead to it. Pair programming, test driven development (TDD), refactoring and code reviews among others, bring a set of very important advantages like collective code ownership, improved code design, living documentation (tests) and automated regression test suites (more on this on Agile code).\nReturning to the original question, in my opinion, technical background is a critical skill for a scrum master. Things are rarely black or white, but how is a scrum master coming from (say) a business school able to deeply understand the importance of TDD? Why would she value pair programming against the common belief that it slows the team down? How is she in a position to understand the significance and implications of deploying on production or how much does a defect cost and how it should be prioritized and treated by the team?\nNow, don\u0026rsquo;t get me wrong. I don\u0026rsquo;t mean that the scrum master should be an expert software engineer, but a decent level of familiarization with the complex field of software engineering would be really beneficial to the team.\nOf course, the team itself should be primarily responsible for these techniques, but I wouldn\u0026rsquo;t want a scrum master just to set the meetings up, book the room and bring the sticky notes. I want one who is enabling the team to work in a better, more efficient way. One that is coaching the team members and guards the process and practices in a meaningful way, encouraging increased code quality.\nThis post is based on a presentation I gave on the 39th Athens Agile/Scrum Meetup\n","date":"2018-06-22T00:00:00Z","image":"//localhost:1313/img/posts/extra_mile.jpg","permalink":"//localhost:1313/technical-background-the-extra-mile-on-scrum-mastery/","title":"Technical background: the extra mile on scrum mastery"},{"content":"Over the years, I have identified a number of issues with the way most companies treat their tests. I have come to believe that the most important one is that test code is treated as a second class citizen. Developers usually opt for the cheap, quick-and-dirty solutions when it comes to writing (or maintaining) tests, not realizing their importance. However, test code has to be designed, reviewed and refactored, exactly like production code. What we usually fail to realize is that the way we write tests reflects on the quality of our production code, allows bugs to creep in and drives design decisions.\n# Two approaches In this post I will delve into the topic of testing behavior as opposed to testing implementation. So, let\u0026rsquo;s elaborate a bit on these two fundamentally different styles. When testing behavior, we\u0026rsquo;re thinking:\nI want to verify that, under these circumstances, the result of an action is this\nTesting for state on the other hand, means thinking:\nI want to verify that, under these circumstances, these actions take place to reach to the result\nObviously, the approach is utterly different, but the gold is to understand the consequences of following one or the other. Before we work the trade-offs, let\u0026rsquo;s illustrate the two styles via a simplified example.\n# Example Assuming we have a unit that fetches all employees from the database, calculates their average salary and sends an e-mail with this number on the subject line. A test-implementation logic could lead us to verify that the number of the fetched employees is correct by asserting on the size of a list data structure, the correct employees with the correct salaries are retrieved, the average salary is correct after taking into account each employee etc.\nOn the other hand, a test-behavior mentality would probably result in executing the method and checking that the send() method was executed in the e-mail service collaborator with the correct argument for the subject parameter.\n# Trade-offs We should always keep in mind that when it comes to software engineering, there is no silver bullet. A great part of our job is to recognize the trade-offs when they present themselves and decide responsibly, living with the consequences. Having said this, both approaches would work, leading to - most probably - different implementations and different ramifications when it comes to flexibility and maintenance.\n# Refactoring One of the most common pitfalls is to couple too tight our tests with the production code. What would happen in the first approach (test-implementation) when, in the future we decide to dump the list and use a different data structure? Our test (that asserts on the list size and contents) will fail to compile. We will be forced to refactor the test along with the production code, immediately jeopardizing our whole refactoring process. Let me elaborate on this topic.\nWhen refactoring a piece of code, we intend to alter its structure but not its behavior.\nIn order to do so, given that the result of any action under the same circumstances remains unaffected, we should be able to rely on our tests to know that we did not change the behavior indeed. However, if we modify our tests, we run the risk of unwittingly modifying what we\u0026rsquo;re testing, allowing bugs to creep in the production code.\nWe may stay clear from this danger applying the test-behavior logic. In this case, the tests do not \u0026ldquo;see\u0026rdquo; the actual implementation and since the results of the actions remain unchanged, the tests remain unaffected and we can make sure we keep them green in each and every refactoring move we make.\n# Ripple effects In my blog post on unit testing best practices I referred to isolation as key property of unit tests. I stated that if a test fails, \u0026ldquo;it should clearly declare a single aspect of the software that is not functioning properly and point us to it immediately\u0026rdquo;. In this post I was referring to leaving the system in the state that we found it, but the isolation principle may be violated in other ways too.\nWhen testing the implementation, we usually instantiate all the collaborators (dependencies) of the class we\u0026rsquo;re testing, whereas, when testing the behavior we tend to use test doubles. A side effect of this is that if a bug lies in a collaborator of the class under test, its tests will remain unaffected in the latter approach, but will fail in the former, creating a ripple of failing tests. Among other things, this will lead us into a debugging session in order to understand what is wrong with the system (as opposed to a finger pointing to the - carefully chosen - name of the failing test).\n# Design decisions As I have mentioned earlier in this post, tests drive design decisions. This is an immensely important point, so let me repeat it. Tests shape our production code. I am mostly referring to Test Driven Development here, but we should always refactor a piece of code that is difficult to test, irrelevant of when the tests where written. Therefore, the tests affect the production code even if we don\u0026rsquo;t test-drive it.\nBefore we elaborate, let\u0026rsquo;s tale a step back to consider a basic unit testing tool: test doubles. Gerard Meszaros uses this term to describe an object that is used in place of a real object for testing purposes. Two test double types that we\u0026rsquo;re particularly interested in (for the purposes of this post) are the following:\nStub: In advance specified behavior covering specific answers to specific calls. This is done in order to serve the test and no additional behavior is prescribed. Mock: Specified expectations referring on the reception of specific method calls (potentially with specific arguments) Now, these two different test doubles are mainly used by two different schools of thought.\nClassical TDDers will use real instances of every collaborator involved in the test. When this is either inconvenient or too difficult, a test double will be used, usually a stub.\nMockist TDDers will never instantiate another class besides the one which is under test. Mocks will be used instead.\nThese choices are utterly important. It is easy to understand that the more stubs we use, the more we couple our unit tests with our production code. This happens because, what we\u0026rsquo;re essentially saying when stubbing a class is \u0026ldquo;when this method is called with these arguments, do this\u0026rdquo;. However, this method call is an implementation detail and should we wish to not call this method during a future refactoring, our unit test will fail (or at least will have to be refactored as well, in order to remove the unused stubbing).\nIn addition, a mockist TDDer will (via the usage of mocks instead of real objects) achieve a quite better (ideally perfect) isolation on the unit tests, as opposed to a classical TDDer, who will have to face a ripple of failing tests sooner or later.\nOne of the most important aspects of this topic though is that different choices (stubs instead of mocks, classical TDD instead of mockist TDD) will result in a totally different production code and a totally different code design. Therefore, favoring testing behavior will produce a totally different application, with different trade-offs, different advantages and shortcomings and different code quality. Hence, I believe that it has become apparent by now (if it wasn\u0026rsquo;t already) that these are decisions that we have to thinking very carefully and take very seriously.\n# Conclusion My initial intention behind this blog post was to raise awareness. Test code should not be treated as second class citizen. There are loads of crossroads, decisions and trade-offs out there and I hope that I have made clear that the ramifications are very significant. Favoring testing behavior brings along a series of side effects and in any case, it is a road that, should we decide to follow it, we should do so wittingly and with professionalism.\n","date":"2018-05-23T00:00:00Z","image":"//localhost:1313/img/posts/writing.jpg","permalink":"//localhost:1313/test-behavior/","title":"Test behavior"},{"content":"Designing APIs for inter microservice communication is one of the most difficult aspects of modern software engineering and the reasons range in a very broad spectrum. First of all, microservices is a relatively new trend and virtually everyone in the software engineering community talks about them nowadays. However, I believe that we still don\u0026rsquo;t know what exactly they are (let alone how they will develop in the future) and therefore, we can\u0026rsquo;t always design them in an efficient way. We\u0026rsquo;ve all experienced microservices that weren\u0026rsquo;t so \u0026ldquo;micro\u0026rdquo; after all (how \u0026ldquo;micro\u0026rdquo; they should be anyway?).\nAdding to it, REST is a marvelous architecture (developed back in 2000 by Roy Fielding as part of his doctoral dissertation). However, it is as misunderstood as beautiful. The web is packed of \u0026ldquo;RESTful\u0026rdquo; web services which are not so RESTful after all. The requirement to communicate with such a system can create previously unseen obstacles, making design very challenging. Furthermore, more often than not, the ecosystem in which a microservice is being developed, contains legacy system(s), which impose very difficult constraints to the design, usually leading to exceptions and inconsistencies, which usually lead to problems further down the road.\nAmong others, the above mentioned phenomena, can increase the degree of difficulty of designing a RESTful API for inter microservice communication. In this post, I will endeavor to share my journey and outcome of designing such an API.\n# The case study This example attempts to design an efficient, RESTful API as a solution to the problem of creating a microservice that is responsible for handling the lifecycle of a shopping cart.\n# Assumptions # Authentication - Authorization Throughout this example we consider authentication - authorization functionality to exist and to be provided by a separate microservice. Therefore, a JWT token (or some other token) is supposedly provided by this microservice and included in the Authorization header in all HTTP requests. In addition, we assume that authorization is not required for the HTTP request to list all available products.\n# Requests - Responses body The body (as well as the headers) provided in the following HTTP requests and responses is an example which attempts to meaningfully demonstrate the essence of the argument and by no means are complete or fully functional. For instance, in the list all products response, products are obviously not represented merely by their IDs and prices, but believing that this structure suffices to communicate the essence of the call, they are intentionally left partially complete.\n# API Design decisions Throughout this post, API design is on the spotlight. Neither application design, nor technological decisions (e.g. persistence layer technology) will not be covered since they do not constitute part of the API design.\n# Making some decisions # Which calls Identifying the correct HTTP calls can be trickier than it actually sounds. My advice would be to approach the problem by carefully producing sequence diagrams to cover all the use cases of the new system. Given that we have them, we can proceed to identify the interaction the system will have with the rest of the systems and therefore define the endpoints and HTTP calls that cover these.\n# Persisting data A common misconception concerning REST is that one is not allowed to store any data in order to implement a RESTful web service. This is not quite true. Persisting data is perfectly fine as long as these data do not concern the state of the client. So, persisting the cart data will not make you uncompliant with REST. In essence, what the architecture is trying to achieve is to make each request independent of any sort of state. There lies a fundamental REST aspect: statelessness. So, by all means, we go ahead and persist the cart data in our system.\n# Eager or lazy initialization An interesting decision we have to make is when to initialize the sopping cart. There are two options: we either lazily create the cart the first time we\u0026rsquo;re asked to put a product in it or we eagerly create it with a separate call before we can put any products in it. In the first case, we use one less call, which sounds like a good thing and we do not create a shopping cart for a user that will never put anything in it. However, a small ambiguity is introduced in our put a product in the cart call, since it will return 201 CREATED the first time it is called (as it will also create a resource - the shopping cart) and 200 OK for any subsequent call (since the shopping cart already exists and we\u0026rsquo;re just putting products in it). Although the first two pros seem quite strong, the final decision is to go with the latter approach for clarity reasons.\n# POST without body Often we face a situation in which we wish to either create a resource or trigger an action, but there are no data to be submitted to the system. We might get tempted to use a GET request, since the request will not have any body. However, we should not succumb to it. Using a POST HTTP request (or a PUT one, depending on the situation) without a body for these purposes is perfectly fine. Beware though that, in such cases, it is important to remember to include the Content-Length header with value 0, since its absence may cause problems to proxies. This is demonstrated both in the request to create a shopping cart and in the one that triggers the checkout.\n# HTTP methods # List all products A GET HTTP request is sent to retrieve all the available products. A list of all available products is returned.\n# Request GET /products Content-type: application/json Accept: application/json # Response 200 OK Content-type: application/json { \u0026#34;products\u0026#34;: [ { \u0026#34;id\u0026#34;: 298743, \u0026#34;price\u0026#34;: { \u0026#34;total\u0026#34;: 23, \u0026#34;tax\u0026#34;: 6, \u0026#34;currency\u0026#34;: EUR } }, { \u0026#34;id\u0026#34;: 287543, \u0026#34;price\u0026#34;: { \u0026#34;total\u0026#34;: 14, \u0026#34;tax\u0026#34;: 3, \u0026#34;currency\u0026#34;: EUR } } ] } # Create a shopping cart A POST HTTP request is sent. A shopping cart is created. The Location header is used to link to the newly created resource (the cart) in order for the client to be able to access it without querying anew.\n# Request POST /cart Authorization: Bearer eyJhbGciOiNIUzI1JiIXVCJ9...TJVA95OrM7E20RMHrZDcEfxjoIZgeFONFh7HgQ Content-type: application/json Accept: application/json Content-Length: 0 # Response 201 Created Content-type: application/json Location: /cart/{cart_id} # Put a product in the cart A POST HTTP request is used to put a product in the cart. The product is sent as part of the request body. The reply contains all cart data in order not to force the client to query again for it.\n# Request POST /cart/{cart_id} Authorization: Bearer eyJhbGciOiNIUzI1JiIXVCJ9...TJVA95OrM7E20RMHrZDcEfxjoIZgeFONFh7HgQ Content-type: application/json Accept: application/json # Response 200 OK Content-type: application/json { \u0026#34;cart_id\u0026#34;: 174826, \u0026#34;products\u0026#34;: [ { \u0026#34;id\u0026#34;: 298743, \u0026#34;quantity\u0026#34;: 1 }, { \u0026#34;id\u0026#34;: 287543, \u0026#34;quantity\u0026#34;: 1 } ], \u0026#34;payment\u0026#34;: { \u0026#34;total\u0026#34;: 74, \u0026#34;tax\u0026#34;: 17, \u0026#34;currency\u0026#34;: EUR } } # Get cart contents A GET HTTP request is used to fetch the contents of a shopping cart.\n# Request GET /cart/{cart_id} Authorization: Bearer eyJhbGciOiNIUzI1JiIXVCJ9...TJVA95OrM7E20RMHrZDcEfxjoIZgeFONFh7HgQ Content-type: application/json Accept: application/json # Response 200 OK Content-type: application/json { \u0026#34;cart_id\u0026#34;: 174826, \u0026#34;products\u0026#34;: [ { \u0026#34;id\u0026#34;: 298743, \u0026#34;quantity\u0026#34;: 1 }, { \u0026#34;id\u0026#34;: 287543, \u0026#34;quantity\u0026#34;: 1 } ], \u0026#34;payment\u0026#34;: { \u0026#34;total\u0026#34;: 74, \u0026#34;tax\u0026#34;: 17, \u0026#34;currency\u0026#34;: EUR } } # Checkout A POST HTTP request will trigger the checkout action, buying all products currently withing this cart.\n# Request POST /cart/{cart_id}/checkout Authorization: Bearer eyJhbGciOiNIUzI1JiIXVCJ9...TJVA95OrM7E20RMHrZDcEfxjoIZgeFONFh7HgQ Content-type: application/json Accept: application/json Content-Length: 0 # Response 200 OK Content-type: application/json # Conclusion Designing RESTful APIs is often misunderstood or poorly performed. However, REST is truly a gift, leveraging our systems architecture and using it right can prove gold for our microservices. As usually, there is not a single approach to the problem of designing a RESTful API, but it is worthwhile to think carefully of our decisions, challenge them and try hard to be compliant with the essence of this architecture. The benefits can be of immense value.\n","date":"2018-03-10T00:00:00Z","image":"//localhost:1313/img/posts/shopping_cart.jpg","permalink":"//localhost:1313/designing-a-restful-shopping-cart/","title":"Designing a RESTful shopping cart"},{"content":"As part of the onboarding process of every new developer in Tripsta, I am required to deliver a training on unit testing basics. I would like to share the most valuable techniques, methodologies and best practices that I have collected over the years. I believe that they constitute the pillars of a solid foundation that every developer should have.\nIt may be a bit unconventional (the way I love it), but before we even start, let me clarify the two most important things that tests are not.\nTests are not nice to have\nTests are not negotiable\nWhen I hear phrases like \u0026ldquo;If we have time, we\u0026rsquo;ll write some tests too\u0026rdquo; or \u0026ldquo;It costs 13 story points, but since there is no time, we can make it 8 if we don\u0026rsquo;t write tests\u0026rdquo; I want to quit my job and sell greengrocery for a living. Tests should be an integral part of writing software.\nI could use a lot of lines talking about the necessity of writing unit tests, the benefits they provide and how they should be an integral part of the software development process instead of just a verification layer (hint: TDD), but that is another blog post on its own. So, let\u0026rsquo;s delve into a handful of best practices which I have come to value over the years.\n# Best practices # Naming Some people are bad at naming. Some other (such as me) are terrible at it. In any case, taking the time to come up with a proper name for everything in our code is worth it. Regardless of how much time we need. Uncle Bob (Robert Martin) likes to say \u0026ldquo;with code, we do more reading than writing, by a huge factor. Which of those operations should be made efficient?\u0026rdquo; Naming matters!! If I were to give you a single piece of advice on naming, it would be the following:\nWrite the tests you\u0026rsquo;d want to read\nBefore stop writing a test and moving to the production code, ask yourself these two questions:\nDoes the test clearly express its behavior? Is it easy to understand? Usually, a developer that struggles to come up with a proper name will settle for a mediocre one, that does not express behavior properly, or even a bad one, which is hard to understand and misleads its reader.\nTests should be a documentation of the module\u0026rsquo;s behavior?\nWhenever we come across a piece of code that we did not write, we want to be able to read its test suite and figure out what this piece of code does. So, take the time (however much you need) to name your tests (and the variables and functions in them) as best as you can and when you come across a mediocre or a bad name, change it to something better (leaving the code cleaner than you found it, as Uncle Bob would say).\nAlso, keep in mind that things change and, especially in the world of computer science, they do so rapidly. There is nothing wrong in starting off with a technique and shifting to a new one when you identify benefits to it. For instance, my team and I worked on a greenfield project almost a year ago and initially adopted the following naming convention:\npublic class AccountTest { @Test public void account_shouldStoreADepositTransaction_whenGivenOne() throws Exception { // Implementation } } This is a very common naming convention. However, after attending a Sandro Mancuso workshop, I was introduced to the following, far better approach, the benefits of which I presented to my team and we shifted to it.\npublic class AccountShould { @Test public void storeADepositTransaction() throws Exception { // Implementation } } So, my advice is to be restless. Scan our (rich) community over the Internet and do not be afraid to shift to new practices and techniques so long as you recognize the value they offer.\n# Isolation This whole point I want to make on isolation can be summarized in the following sentence:\nTests should leave the system in the state that they found it\nThe last thing that we would like to face is 10 failing tests as a result of a single failure that dragged the following 9 tests with it. When we see x tests failing, we should know that there are exactly x problems with the system. Whenever a test is failing, it should clearly declare a single aspect of the software that is not functioning properly and point us to it immediately (by its name and the failure).\nIn order to achieve this, we should ensure that our test, even when it fails, will restore the system to the exact situation it found it and it won\u0026rsquo;t leave it dirty. Each test should not know and care if another one run before it (let alone if it failed or not).\n# Watch the test fail When should we stop writing the test and start writing the production code? That is a surprisingly hard to answer question for a lot of people when I give the training. Take a minute and think about it before reading further on. There are a couple of questions I like asking myself before I stop writing the test.\nDoes it fail for the right reason? What good is a test if it does not break when the functionality breaks? How can we know that this won\u0026rsquo;t happen if we do not watch the test fail and make sure that it fails for the right reason?\nAre the diagnostics clear? There will come a time in the future that this test will break and then someone (most probably us) will have to understand what is wrong and fix it. How hard will it be to fix it if we cannot tell what is wrong? A few months ago, I fell into exactly this pitfall, a test that I had written (quite a few months back) failed against the production code that I had written and all I had in the console was:\nExpected: 1 Got: 0 I forced myself in a debugging session to figure out what was wrong. If only I had taken the time to make the diagnostics clear enough\u0026hellip;\n# Triple A When it comes to designing our unit tests, I strongly recommend that the backbone of the structure should be based on Arrange - Act - Assert (aka AAA). This is a very simple yet solid technique, consisting of the following three steps:\nArrange: Initially, we should prepare the system for the upcoming test, making sure that all preconditions are met.\nAct: Then we should trigger the part of the code that we wish to test.\nAssert: Finally, we should evaluate whether the code meets our expectations or not. This is the point in which a flag should be raised, declaring the outcome of the test and this flag should either be green or red (no yellow or orange results - more on this on the single assertion section).\nLet\u0026rsquo;s consider the following example (I like using a blank line between the three steps, to make the code more readable):\n@Test public void validatorShouldThrowExceptionWhenBookingIDIsNull() throws Exception { Booking booking = BookingBuilder.aBooking().withBookingId(null).build(); Executable validateBooking = () -\u0026gt; bookingValidator.validate(booking); assertThrows(ValidationException.class, validateBooking); } We want to test that a Validator class will throw an exception when validating a booking with null booking ID. In order to achieve this, we need a booking, which has a null booking ID. Given that we have it, we should execute the validate(booking) method, which is the part of the code we wish to verify its functionality. Finally, we want to have a way to know if the code behaved in the expected way (threw a ValidationException), so we write an assertion to expect exactly this.\nSome of the highlight benefits I find in this approach are the following:\nIt promotes a clear separation among the setup, execute and verification steps. A reader who is familiar with this technique can understand the test fast. Code smells in the test become easier to spot (e.g. a series of act-assert steps - more on this on the single assertion section) Discourages overengineering a test by focusing on the the absolutely needed steps to write it. # Single assertion How many assertions should a test have? The answer should always be one. What message is a red bar sending to us? That something is wrong in the system. Which is our reflex move? To find out what is this. This is exactly why we want our tests to be shouting out loud the reason for their failure. If a test fails, we should know, just by reading its name, what the problem is. How can this happen if a test fails for multiple reasons though?\nUnit tests should fail for one and only one reason\nWatch out for a common misconception though. The following test, contains two assertions. Does it violate the single assertion rule?\n@Test public void calculatorShouldGeneratePositiveEvenIntegers() { int number = calculator.generate(); assertThat(number \u0026gt; 0).isTrue(); assertThat(number % 2).isEqualTo(0); } There may be two physical assertions, but they essentially constitute a single logical assertion. This test will fail if and only if the calculator does not generate positive even numbers, as opposed to the following test:\n@Test public void calculatorShouldDivideNumbers() { int number = calculator.divide(2, 2); assertThat(number).isEqualTo(1); Executable divideByZero = () -\u0026gt; calculator.divide(4, 0); assertThrows(ArithmeticException.class, divideByZero); } This test will both fail when calculator fails to divide correctly and when the error case of dividing by zero does not throw an ArithmeticException. Therefore, in essence, we want to avoid a series of act-assert sequences. A single act followed by more than one physical assertions is fine.\n# Assert first Assert first is a technique described in Kent Beck\u0026rsquo;s excellent book Test Driven Development: By Example. As counterintuitive as it may sound (and feel for someone not used to it), it comes with tons of advantages and it will become second nature given some time. The main idea lies in the fact that writing a test presents multiple problems. The two principal ones are \u0026ldquo;what is the right answer?\u0026rdquo; and \u0026ldquo;how am I going to check it\u0026rdquo;. Taking this bottom up approach helps us focus on the target and avoid overengineering the test.\nComing back to the arrange - act - assert example, assuming that I have a business requirement that a booking without booking ID is invalid, and I am writing the booking validator logic, I may start as follows:\n@Test public void validatorShouldThrowInvalidBookingExceptionWhenBookingIdIsNull() { assertThrows(InvalidBookingException.class, validateBooking); } Starting off with the assert, I know both the right answer and how to check it. I am also driven to the proper act for my assertion.\n@Test public void validatorShouldThrowInvalidBookingExceptionWhenBookingIdIsNull() { Executable validateBooking = () -\u0026gt; validator.validate(booking); assertThrows(InvalidBookingException.class, validateBooking); } Now there is only one step missing, the arrange part. I need a booking and it should have a null booking ID.\n@Test public void validatorShouldThrowInvalidBookingExceptionWhenBookingIdIsNull() { Booking booking = BookingBuilder.aBooking().withBookingId(null).build(); Executable validateBooking = () -\u0026gt; validator.validate(booking); assertThrows(InvalidBookingException.class, validateBooking); } Writing a test in this bottom - up fashion seems strange initially, I know. My suggestion would be to give it a shot, stick with it passed the uncomfortable denial phase (the \u0026ldquo;I want to write my tests like I\u0026rsquo;m used to\u0026rdquo; phase), and it will pay off.\n# Conclusion I tried to share some knowledge and some techniques I use when writing unit tests, because I feel that the area is misunderstood. These are the most important topics I wanted to touch, but the list is far from exhaustive.\nWhichever the techniques we might use, let\u0026rsquo;s always keep in mind that tests are an integral part of the system and therefore they should be designed and maintained. We should care for them and we should take the time to write the right tests in the right way.\nP.S. I would also love to cover the whole \u0026ldquo;test state vs test behavior\u0026rdquo; topic, but this post is already lengthy enough and this is a really long topic\n","date":"2018-02-10T00:00:00Z","image":"//localhost:1313/img/posts/test_board.jpg","permalink":"//localhost:1313/unit-testing-best-practices/","title":"Unit testing best practices"},{"content":"During Christmas, just a few days before I decided to take up blogging, I was reading Sandro Mancuso\u0026rsquo;s excellent book Software Craftsmanship. I couldn\u0026rsquo;t help but agree (sometimes even out loud) when reading what Sandro describes as the Agile Hangover. How many companies decide to become agile only to find their projects failing for the very same reasons that urged them to become agile in the first place? What are the common characteristics of so many failed attempts? What is it that goes so wrong anyway?\n# What is Agile anyway? Agile is a notion so frequently used these days in the software engineering industry that has ended up being misunderstood. It would come as no surprise to me if one asked 5 people for the true meaning of this so called agility and gathered 5 different answers. Let me endeavor to explain the way I perceive agile.\nBefore agile, managers and (if lucky) representatives of the development team entered a meeting room in order to discuss (and agree on) any potential aspect and detail of an upcoming project, documenting everything. Then, the development team would come up with a plan to implement everything that document described. Therefore, they would \u0026ldquo;lock\u0026rdquo; themselves up, pursuing the coveted end state, which, of course, was thoroughly described in the document. After the implementation completion (which included a considerably large testing period), the outcome was delivered to the customer, finally engaging in a feedback loop, only to find out that - guess what - change was needed (let alone that half the features were not needed and would never be used). By its nature, this approach is cumbersome and does not embrace change. Locking yourself to a plan and blindly sticking with it jeopardizes becoming outdated with respect to new priorities. Think about it. How soon in the process can the customer realize that a change is needed? How can this be accommodated in the above mentioned life cycle? How can this model deal with changing priorities?\nIn February 2001, seventeen people got together to discuss (what they perceived as) the problem in the way we build software and, by composing the Agile Manifesto, proposed a mindset centered around the creation of a short feedback loop. Therefore, the newly proposed idea proposed that we do not blindly stick to the (long term) plan anymore. We do a little bit of work, involve the customer seeking feedback, inspect the current state, adapt to the feedback and repeat the cycle.\nThe way change is perceived is fundamentally altered, embracing it instead of considering it undesired. Now change is turned into an opportunity.\nIn my opinion, the key difference between the two approaches lies in the fact that agile detaches the software from the illusion of the end state. There is no end state. There will never be one.\nAs long as the business is live, the software lives and evolves with it.\n# Making a company Agile Being influenced is not a bad thing on its own. Blindly (or even worse, dogmatically) embracing a new idea is what I consider one of the greatest pitfalls out there tough. Being influenced is great, so long as one filters and challenges everything. Deciding to undergo the vast transformation that is required for a company in order to become agile needs to go through some extra filtering. Knowing why should it go after such a radical transformation and therefore, what is expected out of it are keys to the its success. Needless to say, just because it is trendy or some other company did it successfully do not suffice as reasoning. Sometimes, a bit of constructive criticism could be just what is needed to get us on the right track on understanding these why and what.\nUsually, companies that haven\u0026rsquo;t got into the trouble of clarifying these why and what prior to embarking on the transformation, find themselves hiring an agile coach who is supposed to magically move his wand, speak the right words and\u0026hellip; boom! We\u0026rsquo;re agile now. More often than not, a few months later, they find themselves with a shiny new process, but writing code in the exact same way and facing the same old problems. A few more months later, they find themselves wondering why this agile transformation did not pay off and why does it still take so long to solve a critical bug on production. Why is there a critical bug on production in the first place?\nDon\u0026rsquo;t get me wrong here. Changing the process is valuable, but we should never forget that the process is a means to an end. The goal is the software! In order to reach the standards we want in software, we should first change the process, but making sure that all along this brings a mindset shifting too. Perhaps hiring an agile coach was the correct move to make after all. However, he should be one with technical expertise, able to lead a mindset shifting, reflecting in the way that code is written in the company. As Albert Einstein would definitely point out, writing code in the same way and expecting different results just because we changed the process is pure insanity.\n# Disciplines During his keynote speech on Agile Greece Summit 2017, Uncle Bob (Robert Martin) talked about a set of disciplines that every developer should follow in order to seal our profession as best as possible from future misfortunes. He even gave us an oath. I will not give you any oath, but I would like to focus on a set of disciplines. Specifically, I would like to shift our attention to the disciplines that will improve the quality of our code. However, before we talk about quality, we should first make sure that we understand it.\nQuality is a very hard to understand notion. What is quality after all? Can one measure it? In my humble opinion, despite the fact that quality is not a tangible entity there are signs that one can notice and know that the situation is improving (happier customers, decreasing maintenance cost, faster features development, less bugs in production just to name a few). I believe that in order to start noticing these sings, we should strive to adhere to a set of disciplines. Extreme programming (XP) comes with a powerful arsenal of practices that can get us on the right track. Let\u0026rsquo;s briefly go over a few:\n# Pair programming If practiced right, it can be one of the most valuable assets of a development team. How many times have you heard a phrase like \u0026ldquo;We have to modify and redeploy the payment module, but Chris is the owner of it and he\u0026rsquo;s out of office today, snorkeling on the reef.\u0026rdquo;? Well, I guess we could either equip Chris with a waterproof mobile or struggle for collective ownership on our code.\nPair programming guarantees this result, along with a series of benefits like improved code design, team cohesion, mentoring and fewer interruptions. Unfortunately, people tend to just sit next to each other and believe that they are practicing pair programming. So, if you do practice it, make sure you do it right. Do you share a common keyboard? Does one focus on the big picture, reviewing every line that the other is typing? Do you trade roles frequently? Perhaps you play ping pong? Do you learn from each other? How often do you switch pairs?\n# Test Driven Development How can we be agile if we don\u0026rsquo;t have an automated suite of tests? If, instead of having self-testing code, manual work is needed to verify that the system behaves as expected? If there is not a single button to verify the whole application and sign it off for production? If testing the whole system requires hours? How agile can we be then?\nTDD is a workflow that emphasizes on making us write the best code that we can write (by constantly asking \u0026ldquo;can you make it better?\u0026rdquo;\u0026quot;). If practiced right, it encourages better design (more cohesive and loosely coupled components), provides documentation (via executable examples, a.k.a. tests) and, when done with a feature, the automated regression test suite comes for free.\nAs if the above mentioned are not sufficient, I could never stress enough the importance of left shift\n# Continuous integration How quickly can we get our latest code, safely to production? How often do we have to integrate our code and face conflicts while doing so? We should always be working on the latest version of the code. We should frequently push to our Version Control Systems (VCS) and check the code out in order to avoid delays and nightmare conflicts later on. Having a continuous integration system helps us work in a more professional way.\n# Code review At least two people should sign the code off. Review the code often. Make sure that the team trusts one another as it will free them to be relentless, which will only work to the team\u0026rsquo;s benefit.\nUse different review styles: over the shoulder review, pair programming or an official session, with the whole team present, dedicated to the task. Whichever the style, review in essence!\nChallenge the code design, propose alternatives and work the trade-offs that they present themselves.\nTalk about performance, maintainability, business needs (without meaning that code formatting for instance should be neglected). Plan a review early enough to provide sufficient time to adapt to changes.\n# Refactoring Martin Fowler, in his wonderful book Refactoring: Improving the Design of Existing Code, explains that before adding a new feature to our system, we should first ask ourselves if the current design of the system is ready to accommodate this new feature. If not, we should refactor it.\nCreate a suite of tests to act as a safety net, change the system in small steps (keeping the tests green in all steps) and make sure that the value of the software increases (other software engineers understand the code, maintenance is easier and development of new features is faster). Keep on doing so mercilessly, until the code meets the requirements.\nMartin Fowler\u0026rsquo;s book is an excellent read and despite being written around the time that the Agile Manifesto was being formed, the ideas in the book are remarkably relevant.\nThese techniques and practices are a few among many, and to go through them all exhaustively would be beyond the scope of this blog post. However, it is vital to understand that they are not an end in itself. The goal is to go out there and experiment with them. Study them and challenge them, but eventually pick the ones that enable us to improve the quality of the software that we produce. Adopt them and use them wisely.\n# Conclusion Being agile is trendy. This is not a bad thing on its own. Deciding to become agile just because it is trendy is truly one of the worst decisions an organization can make. We should investigate and understand the fundamental aspects that it touches before we decide to undergo such a radical transformation. Understanding that software does not have an end state is fundamental. On the contrary, it is like a living organization. It will keep on changing and we will constantly have to reform and reshape it to meet the ever changing business needs. As a matter of fact, the better it meets these needs, the more it will have to change (more feature requests, more traffic etc).\nBecoming agile can be a great leap, but in order for it to be successful, we have to apply the changes deep down to the heart of our organization and not only to its skin. We have to change the mindset of the people and the way we write code. We have to write code in a way that embraces change, in the same way our shiny new process does. We have to go out there and search for the practices that best suit our needs, apply them, learn and start over.\n","date":"2018-01-20T00:00:00Z","image":"//localhost:1313/img/posts/todo.jpg","permalink":"//localhost:1313/agile-code/","title":"Agile code"}]